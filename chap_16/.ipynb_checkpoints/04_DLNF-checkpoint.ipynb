{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569bec07-0709-49e8-a95a-bc6b5aacc855",
   "metadata": {},
   "source": [
    "# DLinear NeuralForecast\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c070ff-97b9-43aa-b6a5-6fe010837767",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a9dd7-4795-4f74-9b67-413cb01a80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install the missing package\n",
    "!pip install neuralforecast\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# OS \n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# JavaScript Object Notation\n",
    "import json\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython & Itertools\n",
    "from itertools import cycle\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Stats Forecast\n",
    "from statsforecast import StatsForecast\n",
    "\n",
    "# NeuralForecast - will work after installation\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast.auto import AutoNBEATS\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "from neuralforecast.auto import AutoNHITS\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "\n",
    "# FuncTools\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da8427-93e3-4704-a628-63af34252d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b83fe2-b2e7-489a-a005-832962689428",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd622f-ba1c-40df-a7ed-391296b00e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_16\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3c9fd-194f-4bf7-b96a-ea8093506481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc4851-89c9-4825-af5d-6cae5bc45f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SUBSAMPLE = True  # Trains a subsample of IDs to improve run speed\n",
    "\n",
    "RETUNE = True  # if false, will use pre-trained hyperparameters when generating the AUTO NeuralForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7ea5b-6c0d-4b81-8a04-676e84acd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = Path(\"data/london_smart_meters/preprocessed\")\n",
    "\n",
    "output = Path(\"data/london_smart_meters/output\")\n",
    "\n",
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663ae72-968e-4d07-9185-922c67a4e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a6511-6747-4c6e-a6e8-3ac399fc6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of IDs Pre-Sampling: \", len(train_df.LCLid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16748def-e62b-4a82-a5d4-44a3c693493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on smaller set of data for daster iteration.\n",
    "if TRAIN_SUBSAMPLE:\n",
    "    print(\"sub sampling\")\n",
    "    SAMPLE = 10\n",
    "    sampled_LCLids = pd.Series(train_df.LCLid.unique().remove_unused_categories().categories).sample(SAMPLE, random_state=99).tolist()\n",
    "    train_df = train_df.loc[train_df.LCLid.isin(sampled_LCLids)]\n",
    "    test_df = test_df.loc[test_df.LCLid.isin(sampled_LCLids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff936d-4ec1-4a2a-af39-8050d07d1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of IDs Post Sampling: \", len(train_df.LCLid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e37212-070b-40ec-bf83-fe2e6450823f",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7cebd-7bcf-4741-b4f5-265d839e6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Min Date: \", train_df.timestamp.min(), \n",
    "      \"\\nTraining Max Date: \", train_df.timestamp.max(), \n",
    "      \"\\nTesting Min Date: \", test_df.timestamp.min(),\n",
    "      \"\\nTesting Max Date: \", test_df.timestamp.max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26569600-a3ed-44e1-ab3b-e2ac3e789984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping 1 days aside as a validation set\n",
    "cutoff = train_df.timestamp.max() - pd.Timedelta(1, \"D\")\n",
    "\n",
    "validation_df = train_df[(train_df.timestamp>cutoff)].reset_index(drop=True) # validation prediction set\n",
    "training_df = train_df[(train_df.timestamp<=cutoff)].reset_index(drop=True) # training set used for validation set\n",
    "\n",
    "print(f\"Train Max: {training_df.timestamp.max()} \\nValidation Min: {validation_df.timestamp.min()} \\nValidation Max: {validation_df.timestamp.max()}\")\n",
    "print(f\"Validation Horizon: {len(validation_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada101fb-6c41-4135-8caa-a555cc0ca24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 48\n",
    "\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b7304-ed03-4b7e-933d-d002915c60f9",
   "metadata": {},
   "source": [
    "## Training DLinear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc453c-82d2-4986-b2e6-9fe3e502256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[['LCLid']].nunique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d6416-4734-4454-b0f3-af45d72fc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_df['LCLid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebbdfe6-6983-4c9a-b3e1-fc31b6e05baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_untuned = [DLinear (h=h, input_size = 48*7, \n",
    "                max_steps = max_steps)]\n",
    "\n",
    "model_untuned = NeuralForecast(models=model_untuned, freq='30min')\n",
    "\n",
    "model_untuned.fit(training_df[['LCLid','timestamp','energy_consumption']],\n",
    "                  id_col = 'LCLid',\n",
    "                  time_col = 'timestamp',\n",
    "                  target_col='energy_consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b6b0db-84fd-45cb-8a70-b0afceed7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions for validation\n",
    "pred_df =  model_untuned.predict(futr_df=validation_df[['LCLid','timestamp','energy_consumption']]).reset_index()\n",
    "pred_df = pred_df.merge(validation_df[['LCLid','timestamp','energy_consumption']], on=['LCLid','timestamp'], how='left')\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76d085-f2d6-465e-9885-1095000166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "StatsForecast.plot(validation_df[['LCLid','timestamp','energy_consumption']], \n",
    "                   pred_df, engine='matplotlib', \n",
    "                   id_col='LCLid',\n",
    "                   time_col= 'timestamp', \n",
    "                   target_col='energy_consumption',\n",
    "                   models=['DLinear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef624c-9688-4aaf-8023-7363686051d9",
   "metadata": {},
   "source": [
    "#### Evaluate DLinear Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822d040-40c1-424d-be93-51a9475cdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_mase = partial(mase, seasonality=48)\n",
    "\n",
    "# Get metrics for individual LCLid's\n",
    "DLinear_metrics = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption'\n",
    "        )\n",
    "\n",
    "# Get aggregated metrics for across all LCLid's by model\n",
    "DLinear_metrics_agg = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        agg_fn='mean'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fe41d-5db0-4252-a78d-3a93b215d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLinear_metrics_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47d4a7-554a-4a71-8e31-e6c63a2c712d",
   "metadata": {},
   "source": [
    "### DLinear Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5ca93-f554-4fdd-9ea4-7a33ee32d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "config_file_path = 'notebooks/Chapter16/saved_params_config/DLinear_best_config.json'\n",
    "try:\n",
    "    with open(config_file_path, 'r') as config_file:\n",
    "        loaded_config = json.load(config_file)\n",
    "        print(loaded_config)\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. \n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53742a5-b494-4587-a1fe-4ca80fd0685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLinear_config = {\n",
    "    \"max_steps\": max_steps,  # This parameter can be adjusted if needed\n",
    "    \"input_size\": tune.choice([h,h*7,h*7*2,h*7*3]), # Size of input window\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-1),  # Initial learning rate\n",
    "    \"scaler_type\": tune.choice([\"minmax\", \"standard\"]),\n",
    "    \"batch_size\": tune.choice([32, 64,128, 256]),\n",
    "    \"random_seed\": tune.choice([10, 20,30]),\n",
    "}\n",
    "\n",
    "if RETUNE == True:\n",
    "    models = [AutoDLinear(h=h, \n",
    "                     config = DLinear_config,\n",
    "                     search_alg = HyperOptSearch(),\n",
    "                     backend = 'ray',\n",
    "                     num_samples = 100,\n",
    "                     #cpus=10, \n",
    "                     )]\n",
    "\n",
    "else:\n",
    "    models = [AutoDLinear(h=h, \n",
    "                    config = loaded_config,\n",
    "                    search_alg = None,\n",
    "                    backend = 'ray',\n",
    "                    #cpus=1\n",
    "                    )]\n",
    "\n",
    "\n",
    "model_tuned = NeuralForecast(models=models, freq='30min')\n",
    "\n",
    "model_tuned.fit(training_df[['LCLid','timestamp','energy_consumption']],\n",
    "                id_col = 'LCLid',\n",
    "                time_col = 'timestamp',\n",
    "                target_col='energy_consumption',\n",
    "                val_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bac838-b69d-4d1d-ae65-c1e2b6f204ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_test =  models_test.predict(futr_df=test_df[['LCLid','timestamp','energy_consumption']]).reset_index()\n",
    "pred_df_test = pred_df_test.merge(test_df[['LCLid','timestamp','energy_consumption']], on=['LCLid','timestamp'], how='left')\n",
    "pred_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cff41-69bd-407a-b413-13c3507ceb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_mase = partial(mase, seasonality=48)\n",
    "\n",
    "# Get metrics for individual LCLid's\n",
    "DLinear_metrics_test = evaluate(pred_df_test, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption'\n",
    "        )\n",
    "\n",
    "# Get aggregated metrics for across all LCLid's by model\n",
    "DLinear_metrics_agg_test = evaluate(pred_df_test, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        agg_fn='mean'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1267f1-640c-44ba-9842-974bb50b9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLinear_metrics_agg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8989493-903d-4049-953b-59d3117895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLinear_metrics_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d42530-03cd-4c3f-a1a4-a3d61be14d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLinear_metrics_agg_test.to_pickle(output/'DLinear_metrics_agg_test.pkl')\n",
    "DLinear_metrics_test.to_pickle(output/'DLinear_metrics_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e776712-9787-4dfd-8698-7d03e56a1af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
