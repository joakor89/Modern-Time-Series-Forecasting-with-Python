{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b643242a-3ff0-4372-b1b8-cdbea17869bf",
   "metadata": {},
   "source": [
    "# `NHITS` with NeuralForecast\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938918af-98b4-4c2e-b6b5-f21bda271e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bbfaf-dcd4-4c9b-8fe9-d6d392c7a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install the missing package\n",
    "!pip install neuralforecast\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# OS \n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# JavaScript Object Notation\n",
    "import json\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython & Itertools\n",
    "from itertools import cycle\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Stats Forecast\n",
    "from statsforecast import StatsForecast\n",
    "\n",
    "# NeuralForecast - will work after installation\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast.auto import AutoNBEATS\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "from neuralforecast.auto import AutoNHITS\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "\n",
    "# FuncTools\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73399b-94ac-4871-85ec-aa24d7984c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import rmse, mae, mse, mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361ddf3-6248-4dd3-8db0-040f7937ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2c4be-6cc9-470f-a7fc-8a64dc98044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562b8c3-26d4-45e6-830d-bafa8294eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_16\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d2590-d920-403f-b477-b1c657d071e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SUBSAMPLE = False  # Trains a subsample of IDs to improve run speed\n",
    "\n",
    "RETUNE = True  # if false, will use pre-trained hyperparameters when generating the AUTO NeuralForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f22f19-b67b-41ce-bb51-ebfdf61bca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = Path(\"data/london_smart_meters/preprocessed\")\n",
    "output = Path(\"data/london_smart_meters/output\")\n",
    "\n",
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3de717-3547-4987-af5d-d4ce9f4874db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064ba8f-81d9-4880-acc3-0b532e5e958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of IDs Pre-Sampling: \", len(train_df.LCLid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bca8b-2d4c-46e5-a8d5-b5e4c07b5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df,\n",
    "                   engine='matplotlib',\n",
    "                   id_col='LCLid',\n",
    "                   time_col= 'timestamp',\n",
    "                   target_col='energy_consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc349d46-267c-4c8c-8d2d-891fdf3ad016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on smaller set of data for daster iteration.\n",
    "if TRAIN_SUBSAMPLE:\n",
    "    print(\"sub sampling\")\n",
    "    SAMPLE = 10\n",
    "    sampled_LCLids = pd.Series(train_df.LCLid.unique().remove_unused_categories().categories).sample(SAMPLE, random_state=99).tolist()\n",
    "    train_df = train_df.loc[train_df.LCLid.isin(sampled_LCLids)]\n",
    "    test_df = test_df.loc[test_df.LCLid.isin(sampled_LCLids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13c224-ace1-4b0a-9abd-3fba92056e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of IDs Post Sampling: \", len(train_df.LCLid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4a352-c648-40a2-b0cd-07c68599acec",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68c382-02a9-4632-91b8-46df67d78879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Min Date: \", train_df.timestamp.min(), \n",
    "      \"\\nTraining Max Date: \", train_df.timestamp.max(), \n",
    "      \"\\nTesting Min Date: \", test_df.timestamp.min(),\n",
    "      \"\\nTesting Max Date: \", test_df.timestamp.max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc34c5-be8a-426e-802b-f6428ea89b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping 1 days aside as a validation set\n",
    "cutoff = train_df.timestamp.max() - pd.Timedelta(1, \"D\")\n",
    "\n",
    "validation_df = train_df[(train_df.timestamp>cutoff)].reset_index(drop=True) # validation prediction set\n",
    "training_df = train_df[(train_df.timestamp<=cutoff)].reset_index(drop=True) # training set used for validation set\n",
    "\n",
    "print(f\"Train Max: {training_df.timestamp.max()} \\nValidation Min: {validation_df.timestamp.min()} \\nValidation Max: {validation_df.timestamp.max()}\")\n",
    "print(f\"Validation Horizon: {len(validation_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752f632-57a5-43f2-8ba1-eacc31ded290",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 48\n",
    "\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e91c4d-88cb-4c14-b095-10617db8ab93",
   "metadata": {},
   "source": [
    "### Training NHITS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85d15a-ce5f-4a89-a546-6e341d58eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_untuned = [NHITS(h=h,  input_size = 48*7,              \n",
    "                max_steps=max_steps)]\n",
    "\n",
    "model_untuned = NeuralForecast(models=model_untuned, freq='30min')\n",
    "model_untuned.fit(training_df[['LCLid','timestamp','energy_consumption']], id_col = 'LCLid',time_col = 'timestamp',target_col='energy_consumption')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163e4be-0d9d-45e7-9293-5ef052a66eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions for validation\n",
    "pred_df =  model_untuned.predict(futr_df=validation_df[['LCLid','timestamp','energy_consumption']]).reset_index()\n",
    "pred_df = pred_df.merge(validation_df[['LCLid','timestamp','energy_consumption']], on=['LCLid','timestamp'], how='left')\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760020a9-fa03-453d-9a92-29dca51b8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize results\n",
    "StatsForecast.plot(validation_df[['LCLid','timestamp','energy_consumption']], \n",
    "                   pred_df, engine='matplotlib', \n",
    "                   id_col='LCLid',\n",
    "                   time_col= 'timestamp', \n",
    "                   target_col='energy_consumption',\n",
    "                   models=['NHITS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd57834-7afd-4f2e-aed8-89b36f00c5d0",
   "metadata": {},
   "source": [
    "#### Evaluate `NHITS` Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954a792-c65e-4dd3-807c-84c8bf2b872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_mase = partial(mase, seasonality=48)\n",
    "\n",
    "# Get metrics for individual LCLid's\n",
    "NHITS_metrics = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption'\n",
    "        )\n",
    "\n",
    "# Get aggregated metrics for across all LCLid's by model\n",
    "NHITS_metrics_agg = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        agg_fn='mean'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77676241-afd4-4a27-a884-fb17afbf63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NHITS_metrics_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b76519-f04b-434f-bf43-84ab1ffb22f4",
   "metadata": {},
   "source": [
    "### NHITS Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f816f19-3317-493c-96da-ffe0c8c68a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "config_file_path = 'notebooks/Chapter16/saved_params_config/NHITS_best_config.json'\n",
    "try:\n",
    "    with open(config_file_path, 'r') as config_file:\n",
    "        loaded_config = json.load(config_file)\n",
    "        print(loaded_config)\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. \n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f56ee2-4878-48ea-b889-c26e21952cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NHITS_config = {\n",
    "    \"max_steps\": max_steps,  # This parameter can be adjusted if needed\n",
    "    #\"input_size\": 48*7*2,  # Size of input window\n",
    "    \"input_size\": tune.choice([h,h*7,h*7*2,h*7*3]),\n",
    "    \"learning_rate\": tune.loguniform(1e-2, 1e-1),  # Initial learning rate\n",
    "    \"scaler_type\": tune.choice([\"minmax\", \"robust\", \"standard\"]),\n",
    "    #\"dropout_prob_theta\":tune.uniform(0, .1),\n",
    "    \"batch_size\": tune.choice([32, 64])    \n",
    "}\n",
    "\n",
    "if RETUNE == True:\n",
    "    models = [AutoNHITS(h=h, \n",
    "                     config = NHITS_config,\n",
    "                     search_alg = HyperOptSearch(),\n",
    "                     backend = 'ray',\n",
    "                     num_samples = 100,\n",
    "                     cpus=1)]\n",
    "\n",
    "else:\n",
    "    models = [AutoNHITS(h=h, \n",
    "                    config = loaded_config,\n",
    "                    search_alg = None,\n",
    "                    backend = 'ray',\n",
    "                    cpus=1)]\n",
    "\n",
    "\n",
    "model_tuned = NeuralForecast(models=models, freq='30min')\n",
    "model_tuned.fit(training_df[['LCLid','timestamp','energy_consumption']], id_col = 'LCLid',time_col = 'timestamp',target_col='energy_consumption', verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01529a-777e-4c7a-9692-23b65d88d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETUNE == True:\n",
    "    NHITS_best_config = model_tuned.models[0].results.get_best_result().config\n",
    "\n",
    "    # Remove specific keys using the pop method and then saving so we can extract parameters later\n",
    "    NHITS_best_config.pop(\"loss\", None)\n",
    "    NHITS_best_config.pop(\"valid_loss\", None)\n",
    "    NHITS_best_config.pop(\"h\", None)\n",
    "\n",
    "    # Save the filtered configuration to a JSON file\n",
    "    with open(config_file_path, 'w') as config_file:\n",
    "        json.dump(NHITS_best_config, config_file, indent=4)\n",
    "\n",
    "    print(\"Best configuration as string:\")\n",
    "    print(NHITS_best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51168c9c-d03b-487d-acea-659ce4042251",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_tuned.models[0].results.get_dataframe()\n",
    "\n",
    "results[['loss', 'train_loss', 'timestamp', \n",
    "       'training_iteration', \n",
    "        'config/max_steps', 'config/input_size',\n",
    "       'config/learning_rate', 'config/h', 'config/loss',\n",
    "       ]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5adf10-2dc5-4405-af2f-e086eec392fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_autoNHITS =  model_tuned.predict(futr_df=validation_df[['LCLid','timestamp','energy_consumption']]).reset_index()\n",
    "pred_df = pred_df_autoNHITS.merge(pred_df[['LCLid','timestamp','energy_consumption','NHITS']], on=['LCLid','timestamp'], how='left')\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2b542-3b36-4244-8ce3-baa29f428c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_mase = partial(mase, seasonality=48)\n",
    "\n",
    "autoNHITS_metrics = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption'\n",
    "        )\n",
    "\n",
    "autoNHITS_metrics_agg = evaluate(pred_df, \n",
    "        metrics=[rmse, mae, mse, fcst_mase],  \n",
    "        train_df = train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        agg_fn='mean'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1bfed-53a2-42a5-827a-74d605bc21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoNHITS_metrics_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba7150-22b7-4db6-a244-1f62d38e5e29",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691997aa-5e76-4b4f-9a9e-e2bdcbbdfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "\n",
    "model_interpretable = model_untuned.models[0]\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df = training_df[training_df.LCLid == training_df.LCLid[0]], id_col='LCLid',time_col='timestamp',target_col='energy_consumption')\n",
    "y_hat = model_interpretable.decompose(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c1c88-878f-4f00-b749-3729ec15eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57b9de-4a46-4cba-bdb6-a66aa5f52a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(6, 7))\n",
    "\n",
    "fig.suptitle(training_df.LCLid[0], fontsize=16)\n",
    "ax[0].plot(validation_df[validation_df.LCLid == training_df.LCLid[0]]['energy_consumption'].values, label='True', linewidth=4)\n",
    "ax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast', color=\"#7B3841\")\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Harmonic Signal')\n",
    "\n",
    "ax[1].plot(y_hat[0,2]+y_hat[0,0], label='stack1', color=\"green\")\n",
    "ax[1].set_ylabel('NHITS Trend Stack')\n",
    "\n",
    "ax[2].plot(y_hat[0,1], label='stack2', color=\"orange\")\n",
    "ax[2].set_ylabel('NHITS Seasonality Stack')\n",
    "ax[2].set_xlabel(r'Prediction $\\tau \\in \\{t+1,..., t+H\\}$')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('imgs/chapter_16/NHITS_interp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c669b8b-4289-446d-bd1c-c59cb9cab59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201dee8-2233-49cb-9b83-b0fdfea2aa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5f7a3-43a6-40e4-8afd-53f1e78e5c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f701b-2dd7-4739-88a0-877f2d6462c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e37032-a283-4862-b6ce-124f018b1bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963c535-60a1-4dcd-ac44-aa27e2d8af77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509180a-1753-4a3e-b57d-76efd74b6e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac0af5-5f3c-4e56-9b6e-a153a34aa8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b47e3-33fc-41e6-887d-655e789c64fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9844bb-8a24-434e-80f0-64204c211d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f9a1d-7b5a-48fa-84d4-38960224a2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657f6e2-b553-451c-bc64-df5f4afb7353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3342306-ac87-496d-b038-4054e326865b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734f123-0203-4566-8435-49532e805679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb6663-e65d-4f17-9024-5089109b66fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9df855-2596-419b-89ac-e12925527fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd539e4c-bb06-474c-b1c0-5cf3b5a7145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
