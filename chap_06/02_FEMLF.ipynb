{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2727387f-6452-4830-90b4-46a60ceb7fd0",
   "metadata": {},
   "source": [
    "# Feature Engineering: `Machine Learning Forecasting`\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c8c65-33c0-4dcd-9b8e-884e036381af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434a3a8-3c00-44f4-a268-19d143ae092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_list_like\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "import humanize\n",
    "\n",
    "# IO & Requests\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# StatsModels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import MSTL , DecomposeResult\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import sys\n",
    "import pickleshare\n",
    "import missingno as msno\n",
    "from itertools import cycle\n",
    "from typing import List, Tuple\n",
    "\n",
    "# PyArrow\n",
    "import pyarrow as pa\n",
    "\n",
    "# FuncTools\n",
    "from functools import partial\n",
    "\n",
    "# Path & Notebook Optimizer\n",
    "from pathlib import Path\n",
    "import missingno as msno\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NIXTLA\n",
    "from statsforecast.core import StatsForecast\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "# Forecast\n",
    "# from datasetsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "from src.utils.general import LogTime\n",
    "from src.utils.data_utils import _get_32_bit_dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0528e5-3676-41f9-a365-dd6c0051895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db868993-933a-43c9-950b-aac598126c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_06\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e97a2f-787d-4d61-ab63-63b7297df3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "sys.path.append('/Users/joaquinromero/Desktop/MTSF') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d1fec-dffc-46a7-9ea0-aa2a8cfc4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.window_ops.rolling import (\n",
    "    seasonal_rolling_max,\n",
    "    seasonal_rolling_mean,\n",
    "    seasonal_rolling_min,\n",
    "    seasonal_rolling_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea0859-9be9-4133-933e-638bb8465d68",
   "metadata": {},
   "source": [
    "### Reading `The Preprocessed Files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d18cd-4fdb-4188-936b-3aca5e7cb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading The Missing Value Imputed and Train/Test Split Data\n",
    "try:\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed.parquet\")\n",
    "    val_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed.parquet\")\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Setting up Experiment Harness.ipynb in Chapter04\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d67bc7-592b-469e-94e4-52e4cd647cab",
   "metadata": {},
   "source": [
    "#### Combining The Train, Validation & Test Datasets for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630355d-a659-4572-9b39-087dfe6947ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"type\"] = \"train\"\n",
    "val_df[\"type\"] = \"val\"\n",
    "test_df[\"type\"] = \"test\"\n",
    "\n",
    "full_df = pd.concat([train_df, val_df, test_df]).sort_values([\"LCLid\", \"timestamp\"])\n",
    "del train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b80ee-5c1d-4ca4-9209-daf026e187b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.lag_transforms import (\n",
    "    RollingMean,\n",
    "    RollingStd,\n",
    "    RollingMin,\n",
    "    RollingMax,\n",
    "    SeasonalRollingMean,\n",
    "    SeasonalRollingMin,\n",
    "    SeasonalRollingMax,\n",
    "    SeasonalRollingStd,\n",
    "    ExponentiallyWeightedMean,\n",
    ")\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ac370-6ea6-48b7-ad16-33a260c03210",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_transforms = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b705517-1b22-450b-bf62-02271903cda8",
   "metadata": {},
   "source": [
    "#### `Lag` Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c00f1-307a-452f-9118-9d23d66495ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = (\n",
    "    (np.arange(5) + 1).tolist()\n",
    "    + (np.arange(5) + 46).tolist()\n",
    "    + (np.arange(5) + (48 * 7) - 2).tolist()\n",
    ")\n",
    "\n",
    "lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de823cf9-5c97-4347-96af-eac70716a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LogTime():\n",
    "#     full_df, added_features = add_lags(\n",
    "#         full_df, lags=lags, column=\"energy_consumption\", ts_id=\"LCLid\", use_32_bit=True\n",
    "#     )\n",
    "# print(f\"Features Created: {','.join(added_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfebaa-e2d6-46c6-bc35-1573f5fa85ba",
   "metadata": {},
   "source": [
    "#### Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4acb55-6477-40e8-9a50-add5fefbfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Rolling Mean, Rolling Std, with an offset of one timestep\n",
    "lag_transforms[1]+= [RollingMean(window_size=n) for n in [3, 6, 12, 48]] + [\n",
    "    RollingStd(window_size=n) for n in [3, 6, 12, 48]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8629a-4919-4a85-847d-b5f86b59c731",
   "metadata": {},
   "source": [
    "#### Seasonal Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0eb731-3701-4a4f-ab63-022d413f7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Seasonal Rolling Mean, Seasonal Rolling Std, with an offset of seasonal period timestep\n",
    "lag_transforms[48]+= [SeasonalRollingMean(season_length=48, window_size=3)] + [\n",
    "    SeasonalRollingStd(season_length=48, window_size=3)\n",
    "]\n",
    "\n",
    "lag_transforms[48 * 7]+= [SeasonalRollingMean(season_length=48 * 7, window_size=3)] + [\n",
    "    SeasonalRollingStd(season_length=48 * 7, window_size=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1316d45-70e7-4183-8464-5576fb63e686",
   "metadata": {},
   "source": [
    "#### EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76803c26-d58a-4846-a56d-ea87d1be6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(25).tolist()\n",
    "\n",
    "plot_df = pd.DataFrame({\"Timesteps behind t\": t})\n",
    "\n",
    "for alpha in [0.3, 0.5, 0.8]:\n",
    "    weights = [alpha * math.pow((1 - alpha), i) for i in t]\n",
    "    span = (2 - alpha) / alpha\n",
    "    halflife = math.log(1 - alpha) / math.log(0.5)\n",
    "    plot_df[f\"Alpha={alpha} | Span={span:.2f}\"] = weights\n",
    "\n",
    "fig = px.line(\n",
    "    pd.melt(plot_df, id_vars=\"Timesteps behind t\", var_name=\"Parameters\"),\n",
    "    x=\"Timesteps behind t\",\n",
    "    y=\"value\",\n",
    "    facet_col=\"Parameters\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    yaxis=dict(\n",
    "        title_text=\"Weights\",\n",
    "        titlefont=dict(size=15),\n",
    "        tickfont=dict(size=15),\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        titlefont=dict(size=15),\n",
    "        tickfont=dict(size=15),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_annotations(font=dict(size=16))\n",
    "fig.write_image(f\"imgs/chapter_06/ewma_weights.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80859168-9089-4364-bf18-7b981479c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Rolling Mean, Rolling Std, with an Offset of One Timestep\n",
    "lag_transforms[1] += [ExponentiallyWeightedMean(alpha=alpha) for alpha in [0.2, 0.5, 0.9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18463aad-ea81-4517-9d83-6118144588cd",
   "metadata": {},
   "source": [
    "#### Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aff75b-968f-438d-b641-c98a6a1d0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features you need in the model\n",
    "# these should either be strings (pandas date function) or functions that take date as an argument\n",
    "temporal_features = [\n",
    "    \"month\",\n",
    "    \"quarter\",\n",
    "    \"is_quarter_end\",\n",
    "    \"is_quarter_start\",\n",
    "    \"is_year_end\",\n",
    "    \"is_year_start\",\n",
    "    \"is_month_start\",\n",
    "    \"is_month_end\",\n",
    "    \"week\",\n",
    "    \"day\",\n",
    "    \"dayofweek\",\n",
    "    \"dayofyear\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27e530-687d-4a17-8b35-0a791293a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LogTime():\n",
    "#     full_df, added_features = add_temporal_features(\n",
    "#         full_df,\n",
    "#         field_name=\"timestamp\",\n",
    "#         frequency=\"30min\",\n",
    "#         add_elapsed=True,\n",
    "#         drop=False,\n",
    "#         use_32_bit=True,\n",
    "#     )\n",
    "# print(f\"Features Created: {','.join(added_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550efca-bd72-4769-b7cc-749eb8b4218a",
   "metadata": {},
   "source": [
    "### Calculating The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7327c3-c98e-4725-a686-2a7ba5beb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9593a1-adfa-46a0-b1aa-ef4420d3a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq='D',\n",
    "    lags=lags, # Defining the Lags we need to create\n",
    "    # Defining some transformations we need to do to the lags (offsets)\n",
    "    lag_transforms=lag_transforms,\n",
    "    date_features=temporal_features, # Defining the date features we need\n",
    ")\n",
    "with LogTime():\n",
    "    full_df = fcst.preprocess(\n",
    "        full_df,\n",
    "        time_col=\"timestamp\",\n",
    "        id_col=\"LCLid\",\n",
    "        target_col=\"energy_consumption\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e3998-3130-4f2d-be29-ffd8abf794e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367ae27-f866-4c89-ab52-257b8b72a362",
   "metadata": {},
   "source": [
    "### Fourier Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b854f10-1f50-444d-ad7a-2eafd826e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering.temporal_features import (\n",
    "    add_fourier_features,\n",
    "    bulk_add_fourier_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91c851-6f3b-43c3-ad31-886939ef455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e36932-f0ef-483b-9f20-9f5e651290ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f4191-a364-441b-93ca-ad12a1152421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efb90d-2602-4e4e-b4ca-00f64a7b3a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c1d53-4fc0-4dd2-92d3-0a2ab991b2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014f32b-4132-457b-8d60-63307cab391a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62242ac7-3fd2-4e36-ba17-636352f29a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00824b38-e72f-4b37-978f-56d73bdf9b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56f9aa-8268-4345-a895-dfd369c9d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbbd4c-dcca-4a56-9979-deffa5773698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
