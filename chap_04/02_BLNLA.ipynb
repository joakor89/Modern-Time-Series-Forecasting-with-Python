{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda58c6e-466c-4303-92a1-b1a075e86e98",
   "metadata": {},
   "source": [
    "# Baseline Forecast using NIXTLA\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e9c73b-8246-4d84-a06d-ae377c00023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab17756-69e3-4592-8170-5135d7cca112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "import humanize\n",
    "\n",
    "# IO & Requests\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# StatsModels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import MSTL , DecomposeResult\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import sys\n",
    "import pickleshare\n",
    "import missingno as msno\n",
    "from itertools import cycle\n",
    "\n",
    "# PyArrow\n",
    "import pyarrow as pa\n",
    "\n",
    "# FuncTools\n",
    "from functools import partial\n",
    "\n",
    "# Path & Notebook Optimizer\n",
    "from pathlib import Path\n",
    "import missingno as msno\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NIXTLA\n",
    "from statsforecast.core import StatsForecast\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from statsforecast.models import (\n",
    "    Naive,\n",
    "    SeasonalNaive,\n",
    "    HistoricAverage,\n",
    "    WindowAverage,\n",
    "    SeasonalWindowAverage,\n",
    "    RandomWalkWithDrift,\n",
    "    HoltWinters,\n",
    "    ETS,\n",
    "    AutoETS,\n",
    "    AutoARIMA,\n",
    "    ARIMA,\n",
    "    AutoTheta,\n",
    "    DynamicTheta,\n",
    "    DynamicOptimizedTheta,\n",
    "    Theta,\n",
    "    OptimizedTheta,\n",
    "    TBATS,\n",
    "    AutoTBATS,\n",
    "    MSTL\n",
    ")\n",
    "\n",
    "# Forecast\n",
    "from datasetsforecast.losses import *\n",
    "\n",
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils.ts_utils import forecast_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8b563-99bc-41de-b2a7-404953ae1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4717ca1-20ab-402f-9477-0f097b8f1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "sys.path.append('/Users/joaquinromero/Desktop/MTSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487eeae4-e709-4858-8974-a3f7f2ac9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"'force_all_finite' was renamed to 'ensure_all_finite'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcd057-4ff3-4909-8db3-d5ce54bb5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Makes it so that The Outputs of The Predict Methods have The ID as a Column \n",
    "# Instead of as The Index\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b026d8-a2d2-4b84-8b41-c9bbfd8f2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_04\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39eb05-683a-4e6f-af5f-19bce4b1835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "        \n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "            font=dict(size=20)\n",
    "        ),\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=dict(text=ylabel, font=dict(size=font_size)),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title=dict(text=xlabel, font=dict(size=font_size)),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e66f48-88fa-4239-89d5-13bed4e634e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(pred_df, forecast_columns, timestamp_col, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    \n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [c.replace(\"rgb\", \"rgba\").replace(\")\", \", <alpha>)\") for c in px.colors.qualitative.Dark2]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    dash_types = cycle([\"dash\", \"dot\", \"dashdot\"])\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=pred_df[mask][timestamp_col], y=pred_df[mask]['energy_consumption'],\n",
    "                             mode='lines', line=dict(color=act_color.replace(\"<alpha>\", \"0.3\")),\n",
    "                             name='Actual Consumption'))\n",
    "    \n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(go.Scatter(x=pred_df[mask][timestamp_col], y=pred_df.loc[mask, col],\n",
    "                                 mode='lines', line=dict(dash=next(dash_types), color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                                 name=display_col))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774fac4-b309-4353-b66f-767fe120f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# from itertools import cycle\n",
    "\n",
    "# def plot_forecast(pred_df, forecast_columns, timestamp_col, forecast_display_names=None):\n",
    "#     # Showed Validated Names \n",
    "#     if forecast_display_names is None:\n",
    "#         forecast_display_names = forecast_columns\n",
    "#     else:\n",
    "#         if not isinstance(forecast_display_names, list):\n",
    "#             forecast_display_names = list(forecast_display_names)\n",
    "#         assert len(forecast_columns) == len(forecast_display_names), \"Display names must match forecast columns\"\n",
    "    \n",
    "#     # Build-Up Null Values Mask\n",
    "#     mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "\n",
    "#     # Switching RGB to RGBA Modifibly Opacity \n",
    "#     def rgba(color, alpha):\n",
    "#         return color.replace(\"rgb\", \"rgba\").replace(\")\", f\", {alpha})\")\n",
    "    \n",
    "#     colors = cycle([rgba(c, \"1.0\") for c in px.colors.qualitative.Dark2[1:]])\n",
    "#     act_color = rgba(px.colors.qualitative.Dark2[0], \"0.3\")\n",
    "#     dash_types = cycle([\"dash\", \"dot\", \"dashdot\"])\n",
    "\n",
    "#     # Figure Build Up \n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Real Line \n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=pred_df.loc[mask, timestamp_col],\n",
    "#         y=pred_df.loc[mask, 'energy_consumption'],\n",
    "#         mode='lines',\n",
    "#         line=dict(color=act_color),\n",
    "#         name='Actual Consumption'\n",
    "#     ))\n",
    "\n",
    "#     # Forecast Lines \n",
    "#     for col, display_name in zip(forecast_columns, forecast_display_names):\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=pred_df.loc[mask, timestamp_col],\n",
    "#             y=pred_df.loc[mask, col],\n",
    "#             mode='lines',\n",
    "#             line=dict(dash=next(dash_types), color=next(colors)),\n",
    "#             name=display_name\n",
    "#         ))\n",
    "\n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cff274-65c1-4b1b-ad57-1f69146896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading The Missing Value Imputed and Train Test Split Data\n",
    "try:\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed.parquet\")\n",
    "    train_df = train_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
    "    val_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed.parquet\")\n",
    "    val_df = val_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed.parquet\")\n",
    "    test_df = test_df[['LCLid',\"timestamp\",\"energy_consumption\",\"frequency\"]]\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: File not found in {preprocessed}. Ensure you've run '01-Setting up Experiment Harness.ipynb' in Chapter 04 and that the file path is correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7867347-a64c-469e-badb-8bc3ea36b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min train_df Date: \" , train_df.timestamp.min())\n",
    "print(\"Max train_df Date: \" , train_df.timestamp.max())\n",
    "print(\"Min val_df Date: \" , val_df.timestamp.min())\n",
    "print(\"Max val_df Date: \" , val_df.timestamp.max())\n",
    "print(\"Min test_df Date: \" , test_df.timestamp.min())\n",
    "print(\"Max test_df Date: \" , test_df.timestamp.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4941c37-d38c-4b08-bb38-546392a4be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.timestamp >'2012-01-01']\n",
    "print(\"Min train_df Date: \" , train_df.timestamp.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970bcc0-e1ae-4057-bfee-9fd5ae171915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking a Single Time Series from The Dataset for Illustration\n",
    "freq = train_df.iloc[0]['frequency']\n",
    "\n",
    "ts_train = train_df.loc[train_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]\n",
    "ts_val = val_df.loc[val_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]\n",
    "ts_test = test_df.loc[test_df.LCLid==\"MAC000193\", ['LCLid',\"timestamp\",\"energy_consumption\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbbefc-392d-4555-8d6e-cae4c372a6ae",
   "metadata": {},
   "source": [
    "### Baseline Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954fdee-42c8-48a0-87aa-37b5572021cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat([ts_train, ts_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec51cb-33f2-46e1-95a6-436d6e3531d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(ts_train, ts_test, models, metrics, freq, level, id_col, time_col, target_col, h, metric_df=None):\n",
    "    if metric_df is None:\n",
    "        metric_df = pd.DataFrame()  # Initialize an empty DataFrame if not provided\n",
    "\n",
    "    results = ts_test.copy()\n",
    "\n",
    "    # Timing dictionary to store train and predict durations\n",
    "    timing = {}\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        evaluation = {}  # Reset the evaluation dictionary for each model\n",
    "\n",
    "        # Start the timer for fitting and prediction\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Instantiate StatsForecast class\n",
    "        sf = StatsForecast(\n",
    "            models=[model],\n",
    "            freq=freq,\n",
    "            n_jobs=-1,\n",
    "            fallback_model=Naive()\n",
    "        )\n",
    "\n",
    "        # Efficiently predict without storing memory\n",
    "        y_pred = sf.forecast(\n",
    "            h=h,\n",
    "            df=ts_train,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "            level=level,\n",
    "        )\n",
    "\n",
    "        # Calculating the duration\n",
    "        duration = time.time() - start_time\n",
    "        timing[model_name] = duration\n",
    "\n",
    "        # Merge prediction results to the original dataframe\n",
    "        results = results.merge(y_pred, how='left', on=[id_col, time_col])\n",
    "\n",
    "        ids = ts_train[id_col].unique()\n",
    "        # Calculate metrics\n",
    "        for id in ids:\n",
    "            temp_results = results[results[id_col] == id]\n",
    "            temp_train = ts_train[ts_train[id_col] == id]\n",
    "            for metric in metrics:\n",
    "                metric_name = metric.__name__\n",
    "                if metric_name == 'mase':\n",
    "                    evaluation[metric_name] = metric(temp_results[target_col].values,\n",
    "                                                    temp_results[model_name].values,\n",
    "                                                    temp_train[target_col].values, seasonality=48)\n",
    "                else:\n",
    "                    evaluation[metric_name] = metric(temp_results[target_col].values, temp_results[model_name].values)\n",
    "            evaluation[id_col] = id\n",
    "            evaluation['Time Elapsed'] = timing[model_name]\n",
    "\n",
    "            # Prepare and append this model's results to metric_df\n",
    "            temp_df = pd.DataFrame(evaluation, index=[0])\n",
    "            temp_df['Model'] = model_name\n",
    "            metric_df = pd.concat([metric_df, temp_df], ignore_index=True)\n",
    "\n",
    "    return results, metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd2503-ff66-41fc-9182-c27ef261b5f4",
   "metadata": {},
   "source": [
    "### Naïve Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec66b5-0565-4d8d-889c-125a43dcd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "results, metrics = evaluate_performance(\n",
    "    ts_train=ts_train, \n",
    "    ts_test=ts_val, \n",
    "    models=[Naive()], \n",
    "    metrics=[mase, mae, mse, rmse, smape, forecast_bias], \n",
    "    freq=freq,\n",
    "    level=[],  # Ensure this is correct or adjust as necessary\n",
    "    id_col='LCLid',\n",
    "    time_col='timestamp',\n",
    "    target_col='energy_consumption',\n",
    "    h=len(ts_val),\n",
    "    metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa88cc-db83-4129-a0a3-42cbc9df4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708ba89-f908-4469-b25c-54f75286e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['Naive']\n",
    "model_display_name = ['Naive']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/naive.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a37a2-2196-4ea9-8188-7133216bbc17",
   "metadata": {},
   "source": [
    "### Seasonal Naïve Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f7d99-fb3b-4c23-98da-0cd0a17a9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train=ts_train, \n",
    "        ts_test=ts_val, \n",
    "        models = [SeasonalNaive(season_length=48*7)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8e55a-82a0-484d-b35d-20e8cf6a8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df1f77-f8ae-4e81-82e7-110e30ceaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['SeasonalNaive']\n",
    "model_display_name = ['SeasonalNaive']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/seasonal_naive.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf29fc6-7b57-4140-9a12-f89818df6927",
   "metadata": {},
   "source": [
    "### Moving Average Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401b5dc-8840-4b9e-ae1f-52ee8cfad78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [WindowAverage(window_size = 48)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f8e97-adad-4bd5-984a-86fa8232183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f85c8-f905-4341-9da9-f1b809c464f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['WindowAverage']\n",
    "model_display_name = ['WindowAverage']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/window_average.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf46cd6-3a5d-42a1-9494-b7677010a733",
   "metadata": {},
   "source": [
    "### Exponential Smoothing Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ad5b8-ebc9-4c4c-baf1-0ecb7c92788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ HoltWinters(error_type = 'A', season_length = 48)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9124695-1d7e-42dd-add5-da1e66593c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39643d5-44f8-4ed9-bb83-84b0353bf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['HoltWinters']\n",
    "model_display_name = ['HoltWinters']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/ets.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a260ff3-8d28-4dce-a1df-a1fbaa7ae3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ AutoETS(model = 'AAA',season_length = 48)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9b076-5ad7-44c1-9a9b-cd5ef7811297",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908dc64f-d8a1-4e3c-b49f-a8ae1e240f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6461f-e41f-4bec-9757-ab1ee05733e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['AutoETS']\n",
    "model_display_name = ['AutoETS']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/ets.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b2e3f-d764-42b7-b067-18b332934c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652a038-b96b-48fa-8d06-5f5d1bc2e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ ARIMA(order = (2,1,1), seasonal_order = (1,1,1), season_length = 48)],\n",
    "        #models = [ ARIMA(order = (0,1,2), seasonal_order = (0,0,2), season_length = 48)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa364f58-ca46-47c1-9b99-35eb0e4e2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7cafd-966b-4ab2-b074-e5abfd68777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['ARIMA']\n",
    "model_display_name = ['ARIMA']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/ARIMA.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda878e9-8a9a-41c1-8dd3-129f684a1d1c",
   "metadata": {},
   "source": [
    "### Sample Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f58127-bfa2-473a-9849-8afc8df3dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf = StatsForecast(\n",
    "#     models=[AutoARIMA( max_p = 2, max_d=1, max_q = 2, max_P=2, max_D = 1, max_Q = 2, \n",
    "#                       start_p = 1, start_q = 1, start_P = 1, start_Q = 1, stepwise = True, season_length=48)],\n",
    "#     freq=freq,\n",
    "#     n_jobs=-1,\n",
    "#     fallback_model = Naive()\n",
    "# )\n",
    "\n",
    "# y_pred = sf.fit( \n",
    "                  \n",
    "#                     df=ts_train,        \n",
    "#                     id_col = 'LCLid',\n",
    "#                     time_col = 'timestamp',\n",
    "#                     target_col = 'energy_consumption',\n",
    "\n",
    "#                     )\n",
    "# sf.fitted_[0,0].model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b265e-44e5-4761-a9cc-7d1cfc92c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'coef': {'ma1': -0.3800676288610244,\n",
    "#   'ma2': -0.25121322485842584,\n",
    "#   'sma1': 0.1300139905884248,\n",
    "#   'sma2': 0.1045851891918472},\n",
    "#  'sigma2': 0.05918752833035802,\n",
    "#  'var_coef': array([[ 7.04752468e-07,  9.11329831e-07,  2.55693473e-07,\n",
    "#          -1.87114423e-06],\n",
    "#         [ 9.11329831e-07,  7.41876851e-06, -3.18464778e-07,\n",
    "#          -8.00782484e-06],\n",
    "#         [ 2.55693473e-07, -3.18464778e-07,  5.50841803e-07,\n",
    "#          -4.88097177e-07],\n",
    "#         [-1.87114423e-06, -8.00782484e-06, -4.88097177e-07,\n",
    "#           1.03626760e-05]]),\n",
    "#  'mask': array([ True,  True,  True,  True]),\n",
    "#  'loglik': -188.2911979664168,\n",
    "#  'aic': 386.5823959328336,\n",
    "#  'arma': (0, 2, 0, 2, 48, 1, 0),\n",
    "#  'residuals': array([ 0.000368  ,  0.01585512, -0.19137661, ..., -0.3180852 ,\n",
    "#         -0.35435519, -0.1594367 ]),\n",
    "#  'code': 2,\n",
    "#  'n_cond': 0,\n",
    "#  'nobs': 35087,\n",
    "# ...\n",
    "#  'bic': 428.9103257852313,\n",
    "#  'aicc': 386.58410626036135,\n",
    "#  'ic': None,\n",
    "#  'xreg': None,\n",
    "#  'x': array([0.368, 0.386, 0.17 , ..., 0.147, 0.111, 0.09 ], dtype=float32),\n",
    "#  'lambda': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35869bb-a8ca-4c67-84e1-bd736197ad63",
   "metadata": {},
   "source": [
    "### Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24f200-b718-4ef2-bd8f-8359bdcae41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ Theta(season_length =48, decomposition_type = 'additive' )], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3aedb-4bf3-4687-ad29-d1fa11f30011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['Theta']\n",
    "model_display_name = ['Theta']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/auto_theta.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8100b-e938-49a6-8716-025cd3461cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ea4-3d42-4d7e-bc92-51373ae51937",
   "metadata": {},
   "source": [
    "### TBATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4587e-9711-43c5-bc51-5d2e7da5704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf = StatsForecast(\n",
    "#     models=[TBATS(seasonal_periods  = 48, use_trend=True, use_damped_trend=True)],\n",
    "#     freq=freq,\n",
    "#     n_jobs=2\n",
    "# )\n",
    "\n",
    "# y_pred = sf.fit( \n",
    "                  \n",
    "#                     df=ts_train,        \n",
    "#                     id_col = 'LCLid',\n",
    "#                     time_col = 'timestamp',\n",
    "#                     target_col = 'energy_consumption',\n",
    "\n",
    "#                     )\n",
    "# sf.fitted_[0,0].model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a711b9-f51d-4c56-986c-d04c6eac0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf = StatsForecast(\n",
    "#     models=[AutoTBATS(seasonal_periods  = 48, use_trend=True, use_damped_trend=True)],\n",
    "#     freq=freq,\n",
    "#     n_jobs=2\n",
    "# )\n",
    "\n",
    "# y_pred = sf.fit( \n",
    "                  \n",
    "#                     df=ts_train,        \n",
    "#                     id_col = 'LCLid',\n",
    "#                     time_col = 'timestamp',\n",
    "#                     target_col = 'energy_consumption',\n",
    "\n",
    "#                     )\n",
    "# sf.fitted_[0,0].model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d55640-7fb3-48fa-ae3e-4144c3ab4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ TBATS(seasonal_periods = [48])], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed4a52-ee0e-4376-ac3a-36c95bc35f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1c805-d12c-4485-a0e6-a7754d226769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['TBATS']\n",
    "model_display_name = ['TBATS']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/auto_tbats.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95e0a6-73b8-4c12-a316-8ed22bad915b",
   "metadata": {},
   "source": [
    "### MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ae129-c694-47d5-83d7-917f6fa317c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = (\n",
    "    evaluate_performance(\n",
    "        ts_train, \n",
    "        ts_val, \n",
    "        models = [ MSTL(season_length = 48)], \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = len(ts_val),\n",
    "        metric_df=metrics  # Pass None or an existing DataFrame if you want to append results\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e378e9e-c473-4b37-9a0d-1ca76a1bb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['MSTL']\n",
    "model_display_name = ['MSTL']\n",
    "\n",
    "fig = plot_forecast(results, forecast_columns=model_name, forecast_display_names=model_display_name, timestamp_col ='timestamp')\n",
    "fig = format_plot(fig, title=f\"{model_name[0]}: \"\\\n",
    "                  f\"MAE: {metrics.loc[metrics.Model==model_name[0]][['mae']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MSE: {metrics.loc[metrics.Model==model_name[0]][['mse']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"MASE: {metrics.loc[metrics.Model==model_name[0]][['mase']].iloc[0].item():.4f} | \"\\\n",
    "                  f\"BIAS: {metrics.loc[metrics.Model==model_name[0]][['forecast_bias']].iloc[0].item():.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "#fig.write_image(\"imgs/chapter_4/auto_tbats.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8e345-8354-49ce-a7c6-bf68c7360011",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_styled = metrics.reset_index(drop=True).style.format({\n",
    "            \"mae\": \"{:.3f}\", \n",
    "            \"mse\": \"{:.3f}\", \n",
    "            \"mase\": \"{:.3f}\", \n",
    "            \"rmse\": \"{:.3f}\", \n",
    "            \"smape\": \"{:.3f}\",            \n",
    "            \"forecast_bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"mae\",\"mse\",\"mase\",\"rmse\",\"smape\",\"Time Elapsed\"])\n",
    "display(metric_styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165fb2c-e83c-4545-8ab1-75ac9115c637",
   "metadata": {},
   "source": [
    "## Validation Set\n",
    "\n",
    "### Running Baseline Forecast for All Consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732431a-046a-4784-ac5f-84ef90a41818",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(train_df.LCLid.unique()[:500]) # slicing dataframe for the sake of time.  May want to consider setting this low if working on a slower machine\n",
    "\n",
    "train_df = train_df[train_df.LCLid.isin(ids)]\n",
    "val_df = val_df[val_df.LCLid.isin(ids)]\n",
    "test_df = test_df[test_df.LCLid.isin(ids)]\n",
    "\n",
    "print(\"Length of validation Data: \", len(val_df[val_df.LCLid =='MAC000948'].LCLid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2883fb-97e0-483b-9974-efe9ff61f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forecasting for Validation Period for TBATS and AutoETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c1e41-60de-4af8-bd4a-c0e3ca42eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_models =  [AutoETS(model = 'AAA',season_length = 48), \n",
    "                      TBATS(seasonal_periods  = 48)]\n",
    "\n",
    "# validation_models = [Naive()]\n",
    "validation_models_names = [model.__class__.__name__ for model in validation_models]\n",
    "metric_df = pd.DataFrame([])\n",
    "h_val = 1488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434e3ea-280a-4ee0-9982-a5c4984e775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggval_metrics = pd.DataFrame()\n",
    "\n",
    "baseline_val_pred_df, aggval_metrics = (\n",
    "    evaluate_performance(\n",
    "        train_df[[\"LCLid\",\"timestamp\",\"energy_consumption\"]], \n",
    "        val_df[[\"LCLid\",\"timestamp\",\"energy_consumption\"]], \n",
    "        models =validation_models, \n",
    "        metrics = [mase, mae, mse, rmse, smape,forecast_bias], \n",
    "        freq = freq,\n",
    "        level = [] ,\n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption',\n",
    "        h = h_val,\n",
    "        metric_df = aggval_metrics\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edb4f4-97d7-411a-ae41-635e0560d6c9",
   "metadata": {},
   "source": [
    "#### Evaluation of Baseline Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c29291-3260-4c44-bf68-f2a1c883f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggval_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49acb9-6dc3-4a01-9ee2-aec6c22b7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val_pred_df[baseline_val_pred_df.LCLid =='MAC000173']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7f31a-2920-498e-ad11-06ed50dc45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggval_metrics[aggval_metrics.Model =='TBATS'].sort_values(by='mase', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4348e-f15d-49d1-9385-14afe312a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoets_val_metric_df = aggval_metrics[aggval_metrics.Model =='AutoETS']\n",
    "overall_metrics_val_autoets = {\n",
    "    \"Algorithm\": \"AutoETS\",\n",
    "    \"MAE\": mae(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values),\n",
    "    \"MSE\": mse(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values),\n",
    "    \"meanMASE\": autoets_val_metric_df.mase.mean(),\n",
    "    \"Forecast Bias\": forecast_bias(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values)\n",
    "}\n",
    "overall_metrics_val_autoets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2096bc-157d-4d6d-97a5-cbcde408e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoets_val_metric_df = aggval_metrics[aggval_metrics.Model =='AutoETS']\n",
    "overall_metrics_val_autoets = {\n",
    "    \"Algorithm\": \"AutoETS\",\n",
    "    \"MAE\": mae(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values),\n",
    "    \"MSE\": mse(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values),\n",
    "    \"meanMASE\": autoets_val_metric_df.mase.mean(),\n",
    "    \"Forecast Bias\": forecast_bias(baseline_val_pred_df.energy_consumption.values, baseline_val_pred_df.AutoETS.values)\n",
    "}\n",
    "overall_metrics_val_autoets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7bb66-21b6-4212-b261-083666380a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val_metrics_df = pd.DataFrame([overall_metrics_val_autoets, overall_metrics_val_tbats])\n",
    "\n",
    "display(baseline_val_metrics_df.style.format({\"MAE\": \"{:.3f}\", \n",
    "                          \"MSE\": \"{:.3f}\", \n",
    "                          \"meanMASE\": \"{:.3f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21161934-8e4c-497c-a595-fcb5e03b8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7f25e-2831-40ec-b49d-8aab47e26574",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aggval_metrics, \n",
    "                   x=\"mase\", \n",
    "                   color=\"Model\",\n",
    "                   pattern_shape=\"Model\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"mase\", ylabel=\"Probability Density\", title=\"Distribution of MASE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,6])\n",
    "# fig.write_image(\"imgs/chapter_4/mase_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a09ee-5c7a-422e-9ccb-92a92742678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aggval_metrics, \n",
    "                   x=\"forecast_bias\", \n",
    "                   color=\"Model\",\n",
    "                   pattern_shape=\"Model\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=250, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"forecast_bias\", ylabel=\"Probability Density\", title=\"Distribution of BIAS in the dataset\")\n",
    "fig.update_layout(xaxis_range=[-200,200])\n",
    "# fig.write_image(\"imgs/chapter_4/bias_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17f5cc-7b78-4ab6-ae9d-9aacd8a4cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aggval_metrics, \n",
    "                   x=\"mae\", \n",
    "                   color=\"Model\",\n",
    "                   pattern_shape=\"Model\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"mae\", ylabel=\"Probability Density\", title=\"Distribution of MAE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1])\n",
    "# fig.write_image(\"imgs/chapter_4/mae_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0010bdb-b1e5-4086-b50a-c997166f7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aggval_metrics, \n",
    "                   x=\"mse\", \n",
    "                   color=\"Model\",\n",
    "                   pattern_shape=\"Model\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"mse\", ylabel=\"Probability Density\", title=\"Distribution of MSE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1.5])\n",
    "# fig.write_image(\"imgs/chapter_4/mse_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20024789-1b12-4dc3-8417-844a411a7fc4",
   "metadata": {},
   "source": [
    "#### Saving The Baseline Forecasts & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fad098-8b65-489d-8935-d3ab251638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/london_smart_meters/output\", exist_ok=True)\n",
    "\n",
    "output = Path(\"data/london_smart_meters/output\")\n",
    "\n",
    "baseline_val_pred_df.to_pickle(output/\"baseline_val_prediction_df.pkl\")\n",
    "baseline_val_metrics_df.to_pickle(output/\"baseline_val_metrics_df.pkl\")\n",
    "aggval_metrics.to_pickle(output/\"baseline_val_aggregate_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026b86b-7ffa-47af-a664-c945a7ea8dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04a9b4-ba4f-4cb7-8740-546833300d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4162e5-4356-4c5e-9180-8f22545227f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "830652f3-bac8-499d-90f4-3978f25d342e",
   "metadata": {},
   "source": [
    "## Test Set\n",
    "\n",
    "### Forecasting for Test Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287a092-e2eb-439e-a995-e94737b3d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import rmse as rmse_local\n",
    "from utilsforecast.losses import mae as mae_local\n",
    "from utilsforecast.losses import mse as mse_local\n",
    "from utilsforecast.losses import mase as mase_local\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b9cca-cbf4-439a-8a3f-6fb3525f7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df = pd.concat([train_df, val_df])\n",
    "print(\"Length of training Data: \", len(test_df[test_df.LCLid =='MAC000948'].LCLid))\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0627e8-46be-4bb4-9228-0ab18cd248b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models =  [ AutoETS(model = 'AAA',season_length = 48), TBATS(seasonal_periods  = 48)]\n",
    "h_test = 1296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae2cbb-ac72-4b46-804e-e48a0c3733c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StatsForecast(\n",
    "    models=test_models,\n",
    "    freq=freq,\n",
    "    n_jobs=-1,\n",
    "    fallback_model= SeasonalNaive(season_length=48)\n",
    ")\n",
    "\n",
    "# sf.fit( df = _train_df[['timestamp', 'LCLid', 'energy_consumption']] ,    \n",
    "#         id_col = 'LCLid',\n",
    "#         time_col = 'timestamp',\n",
    "#         target_col = 'energy_consumption',\n",
    "#         )\n",
    "\n",
    "# baseline_test_pred_df = sf.predict( h =1296 )\n",
    "\n",
    "# Memory efficient predictions\n",
    "baseline_test_pred_df = sf.forecast(df=_train_df, \n",
    "                                        h=h_test, \n",
    "                                        level=[],   \n",
    "                                        id_col = 'LCLid',\n",
    "                                        time_col = 'timestamp',\n",
    "                                        target_col = 'energy_consumption',\n",
    "        )\n",
    "baseline_test_pred_df = pd.merge(baseline_test_pred_df, test_df[['timestamp', 'LCLid', 'energy_consumption']], on = ['LCLid','timestamp'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946f201-067a-4f2b-870e-9bc7a8ae3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a018f98-78c0-4a0a-bac8-7e7d276228ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_mase = partial(mase_local, seasonality=48)\n",
    "\n",
    "baseline_test_metrics_df = evaluate(baseline_test_pred_df, \n",
    "        metrics=[rmse_local, mae_local, mse_local,fcst_mase],  \n",
    "        train_df = _train_df[['timestamp', 'LCLid', 'energy_consumption']],      \n",
    "        id_col = 'LCLid',\n",
    "        time_col = 'timestamp',\n",
    "        target_col = 'energy_consumption'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297a538-d2f1-4689-8348-ca88f5e67fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1c332-07e0-4b95-b94f-2bedfe2f20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude  = ['LCLid', 'metric']\n",
    "test_columns = [col for col in baseline_test_metrics_df.columns if col not in cols_to_exclude]\n",
    "test_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a7a76-131c-49d4-b0f7-6c015911d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_metrics_df = pd.melt(baseline_test_metrics_df, id_vars = ['LCLid','metric'],value_vars= test_columns, var_name='Algorithm' , value_name='value')\n",
    "baseline_test_metrics_df = baseline_test_metrics_df.pivot_table(index = ['LCLid','Algorithm'], columns = 'metric', values = 'value').reset_index()\n",
    "baseline_test_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e5f10-c4ea-4ede-90c9-584bfdfc5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_models_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e144bf-29fe-4e42-9433-be31261797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0b616-56f6-412d-98d7-eb5597fa188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.losses import *\n",
    "\n",
    "agg_test_metrics = []  # Initialize an empty list to store the metrics dictionaries\n",
    "\n",
    "for model in validation_models_names:\n",
    "    actual_series = baseline_test_pred_df['energy_consumption'].values\n",
    "    pred_series = baseline_test_pred_df[model].values\n",
    "    \n",
    "    # Create a dictionary for the current model's metrics\n",
    "    agg_test_metrics1 = {\n",
    "        \"Algorithm\": model,\n",
    "        \"MAE\": mae(actual_series, pred_series),\n",
    "        \"MSE\": mse(actual_series, pred_series),\n",
    "        \"meanMASE\": baseline_test_metrics_df[baseline_test_metrics_df.Algorithm == model].mase.mean(),\n",
    "        \"Forecast Bias\": forecast_bias(actual_series, pred_series),\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the list\n",
    "    agg_test_metrics.append(agg_test_metrics1)\n",
    "agg_test_metrics_df = pd.DataFrame(agg_test_metrics)\n",
    "agg_test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060e567-a5e1-477c-97b1-94fca5a70253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652ad35-5f66-460c-8184-e791a7f001d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec05451-dad1-4728-9698-81677d89807f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
