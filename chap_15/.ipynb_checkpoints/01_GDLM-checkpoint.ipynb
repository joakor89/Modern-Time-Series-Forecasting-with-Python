{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3af99f-8529-42fd-8801-9387710e4f51",
   "metadata": {},
   "source": [
    "# Global Deep Learning Models\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163b0db0-82c2-43d5-9e9b-340f1675b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0346-8f7e-4cb5-aa30-5aef750f8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# OS \n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython & Itertools\n",
    "from itertools import cycle\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa3115-1d77-4721-9618-cd8f528ca098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils import ts_utils_updated\n",
    "from src.forecasting.ml_forecasting import calculate_metrics\n",
    "\n",
    "from src.forecasting.ml_forecasting import (\n",
    "    MissingValueConfig,\n",
    "    calculate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29612068-6707-4291-814a-6ddf2a58f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53974cb4-26ce-4fe6-96d0-c2ba791e7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f48c6-54db-43fc-80ed-fde4c231b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_15\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8f0f9-da46-42a7-9527-1aa83be0d844",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6365f-2868-41ae-88c4-4e886fe1f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486977b-4997-4291-9a26-da02c15e5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [\n",
    "        \"rgba(\" + \",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)]) + \",<alpha>)\"\n",
    "        for c in px.colors.qualitative.Plotly\n",
    "    ]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pred_df[mask].index,\n",
    "            y=pred_df[mask].energy_consumption,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=act_color.replace(\"<alpha>\", \"0.9\")),\n",
    "            name=\"Actual Consumption\",\n",
    "        )\n",
    "    )\n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pred_df[mask].index,\n",
    "                y=pred_df.loc[mask, col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dot\", color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                name=display_col,\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s.abs() == np.nanmin(np.abs(s.values)), props, '')\n",
    "\n",
    "def evaluate_forecast(pred_df, train_data, fc_column, name, target_name=\"energy_consumption\"):\n",
    "    metric_l = []\n",
    "    for _id in tqdm(pred_df.index.get_level_values(0).unique(), desc=\"Calculating metrics...\"):\n",
    "        target = pred_df.xs(_id)[[target_name]]\n",
    "        _y_pred = pred_df.xs(_id)[[fc_column]]\n",
    "        history = train_data.xs(_id)[[target_name]]\n",
    "        # display(history.tail())\n",
    "        # display(_y_pred.head())\n",
    "        # display(target.head())\n",
    "        metric_l.append(\n",
    "            calculate_metrics(target, _y_pred, name=name, y_train=history)\n",
    "        )\n",
    "    eval_metrics_df = pd.DataFrame(metric_l)\n",
    "    agg_metrics = {\n",
    "            \"Algorithm\": name,\n",
    "            \"MAE\": np.nanmean(np.abs(pred_df[fc_column]-pred_df[target_name])),\n",
    "            \"MSE\": np.nanmean(np.power(pred_df[fc_column]-pred_df[target_name], 2)),\n",
    "            \"meanMASE\": eval_metrics_df.loc[:, \"MASE\"].mean(),\n",
    "            \"Forecast Bias\": 100*(np.nansum(pred_df[fc_column])-np.nansum(pred_df[target_name]))/np.nansum(pred_df[target_name])\n",
    "    }\n",
    "    return agg_metrics, eval_metrics_df\n",
    "\n",
    "#from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "from lightning_fabric.utilities.cloud_io import _load as pl_load\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = pl_load(weight_path)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221ada8-f039-4b05-8ec8-7dc3cc00eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "FeatureConfig = namedtuple(\n",
    "    \"FeatureConfig\",\n",
    "    [\n",
    "        \"target\",\n",
    "        \"index_cols\",\n",
    "        \"static_categoricals\",\n",
    "        \"static_reals\",\n",
    "        \"time_varying_known_categoricals\",\n",
    "        \"time_varying_known_reals\",\n",
    "        \"time_varying_unknown_reals\",\n",
    "        \"group_ids\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad7fb0-b310-44f5-bb5a-9d62d110766c",
   "metadata": {},
   "source": [
    "#### Reading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42152f-6da5-48e6-b404-944202520667",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97441-f204-4b0c-a4d1-19f41b5c9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on smaller set of data for daster iteration.\n",
    "if TRAIN_SUBSAMPLE:\n",
    "    print(\"sub sampling\")\n",
    "    SAMPLE = 10\n",
    "    sampled_LCLids = pd.Series(train_df.LCLid.unique().remove_unused_categories().categories).sample(SAMPLE, random_state=99).tolist()\n",
    "    train_df = train_df.loc[train_df.LCLid.isin(sampled_LCLids)]\n",
    "    test_df = test_df.loc[test_df.LCLid.isin(sampled_LCLids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2fe16-0c8e-4d05-813d-8d1e50f3c516",
   "metadata": {},
   "source": [
    "### Defining The Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7307-3ee9-4b16-becf-04c764af7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    target=\"energy_consumption\",\n",
    "    index_cols=[\"LCLid\", \"timestamp\"],\n",
    "    static_categoricals=[\n",
    "        \"LCLid\",\n",
    "        \"stdorToU\",\n",
    "        \"Acorn\",\n",
    "        \"Acorn_grouped\",\n",
    "        \"file\",\n",
    "    ],  # Categoricals which does not change with time\n",
    "    static_reals=[],  # Reals which does not change with time\n",
    "    time_varying_known_categoricals=[  # Categoricals which change with time\n",
    "        \"holidays\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "    ],\n",
    "    time_varying_known_reals=[  # Reals which change with time\n",
    "        \"apparentTemperature\",\n",
    "    ],  \n",
    "    time_varying_unknown_reals=[  # Reals which change with time, but we don't have the future. Like the target\n",
    "        \"energy_consumption\"\n",
    "    ],  \n",
    "    group_ids=[  # Feature or list of features which uniquely identifies each entity\n",
    "        \"LCLid\"\n",
    "    ],  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d53410-4c42-45b7-b37a-6c4640eab853",
   "metadata": {},
   "source": [
    "#### Creating a Continuous Time Index for PyTorch Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58332bb8-c455-4cd6-ba0d-8636e827a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test with a flag\n",
    "train_df['train'] = True\n",
    "test_df['train'] = False\n",
    "data = pd.concat([train_df, test_df])\n",
    "del train_df, test_df\n",
    "\n",
    "# Adding the time index\n",
    "data['time_idx'] = data.timestamp.apply(lambda x: x.value)\n",
    "diff = data.iloc[1]['time_idx'] - data.iloc[0]['time_idx']\n",
    "data[\"_min_time_idx\"] = data.groupby(\"LCLid\", observed=True)['time_idx'].transform(\"min\")\n",
    "data['time_idx'] = ((data['time_idx']-data['_min_time_idx'])/diff).astype(int)\n",
    "data.drop(columns=\"_min_time_idx\", inplace=True)\n",
    "\n",
    "# separating to train and test\n",
    "train_df = data.loc[data.train]\n",
    "test_df = data.loc[~data.train]\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc43bfb-c4d8-4164-8ec4-78c5c356c142",
   "metadata": {},
   "source": [
    "#### Converting The Categoricals to Object `dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f8782-43e9-4218-9467-b7004c99e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")\n",
    "\n",
    "test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dcaaf-1833-492f-a454-1ac07e6b9a9b",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ec634-dc5a-4541-a44b-dc64adac0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values\n",
    "n = train_df.isna().any()\n",
    "n[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc9b4ad-33f5-4f55-aed3-d4f17a1f96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We aren't using any of these features. So let it be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f45d69-c24f-48bc-8326-0be25371877c",
   "metadata": {},
   "source": [
    "## Training Global Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83d307-d4c8-41f8-8c79-7a28b9eddb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import RMSE, MAE\n",
    "from pytorch_forecasting.data import GroupNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb20b4e-e692-4bde-a231-c85449a0fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e6802-122e-47c8-adb6-45b04afc7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# os.makedirs(\"lightning_logs\", exist_ok=True)\n",
    "# %tensorboard --logdir lightning_logs/\n",
    "\n",
    "# Or start the tensorboard in a separate command prompt/terminal using\n",
    "# tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cc1f3-3020-4833-888b-1d0abc4efccb",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c14c2-21ed-4d5f-8a91-bfc82a9521da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 1\n",
    "max_encoder_length = 48*2\n",
    "\n",
    "batch_size = 512  # set this to a value which your GPU can handle\n",
    "train_model = True # Set this to True to train model. Else will load saved models ! Warning! Training on full dataset takes 3-6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58faab70-c43d-4710-9f08-6505aa59e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record = []\n",
    "\n",
    "individual_metrics = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9d5da-64ed-4f4e-9bcb-5533bd9868af",
   "metadata": {},
   "source": [
    "#### Creating Dataframes for `Train, Val and Test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba17f4-2310-4332-bb41-970ba4979147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.timestamp.max(), test_df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c0f15-8d14-4cff-999f-3c53be75fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(2, \"D\")\n",
    "hist_df = train_df[train_df.timestamp>history_cutoff]\n",
    "\n",
    "print(f\"History Min: {hist_df.timestamp.min()} | Max: {hist_df.timestamp.max()} | Length: {len(hist_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2c719-1494-40e5-a13d-07b73894574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping 1 days aside as a validation set\n",
    "cutoff = train_df.timestamp.max() - pd.Timedelta(1, \"D\")\n",
    "\n",
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(3, \"D\")\n",
    "val_history = train_df[(train_df.timestamp>=history_cutoff)&(train_df.timestamp<=cutoff)].reset_index(drop=True)\n",
    "val_df = train_df[train_df.timestamp>cutoff].reset_index(drop=True)\n",
    "train_df = train_df[train_df.timestamp<=cutoff].reset_index(drop=True)\n",
    "print(\"Split Timestamps:\")\n",
    "print(f\"Train Max: {train_df.timestamp.max()} | Val History Min and Max: {val_history.timestamp.min(), val_history.timestamp.max()} | Val Min and Max: {val_df.timestamp.min(), val_df.timestamp.max()}\")\n",
    "print(f\"Val History Size: {len(val_history.timestamp.unique())} | Val Size: {len(val_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595d43a-7202-4e1f-8f59-cf28298a162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test_df[feat_config.index_cols+[feat_config.target]+['time_idx']].copy()\n",
    "# pred_df.set_index(feat_config.index_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97e21c-d6fb-42c5-a3ba-7226bd72ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feat_config.index_cols + [feat_config.target]\n",
    "full_df = pd.concat(\n",
    "    [\n",
    "        train_df[cols],\n",
    "        val_df[cols],\n",
    "    ]\n",
    ").set_index(feat_config.index_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b6ed0-ccbb-4dd2-b66f-2e4f1683ed81",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb63b60-18d1-4488-b285-c5d6b79b22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"simple\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d1caf-bcfc-44c2-b0f5-13d9b1146787",
   "metadata": {},
   "source": [
    "#### Converting Data into `TimeSeriesDataset` from `PyTorch Forecasting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab1df1-75ff-42fa-a072-d0ef74354cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training dataset\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=feat_config.target,\n",
    "    group_ids=feat_config.group_ids,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"energy_consumption\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=feat_config.group_ids, transformation=None\n",
    "    )\n",
    ")\n",
    "# Defining the validation dataset with the same parameters as training\n",
    "validation = TimeSeriesDataSet.from_dataset(training, pd.concat([val_history,val_df]).reset_index(drop=True), stop_randomization=True)\n",
    "\n",
    "# Defining the test dataset with the same parameters as training\n",
    "test = TimeSeriesDataSet.from_dataset(training, pd.concat([hist_df, test_df]).reset_index(drop=True), stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca9bf9-c119-480c-8175-0e84ad78e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the dataloaders\n",
    "# num_workers can be increased in linux to speed-up training\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f244e9a-7535-4f23-926d-aad7828c54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the dataloader\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")\n",
    "print(\"\\nsize of y =\")\n",
    "print(f\"\\ty = {y[0].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c79257-f901-471b-8cbb-164a2001581c",
   "metadata": {},
   "source": [
    "#### Creating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2a6bb-29da-436d-bd2c-a20c60cc7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the skeleton and helper models from src\n",
    "from src.dl.ptf_models import SingleStepRNN, SingleStepRNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f7e1f-4e5d-4506-9bc3-87d49a072b17",
   "metadata": {},
   "source": [
    "#### Defining The Forward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da4851-52d7-40fa-91d8-9ff5cc81cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class SimpleRNNModel(SingleStepRNN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type: str,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "    ):\n",
    "        super().__init__(rnn_type, input_size, hidden_size, num_layers, bidirectional)\n",
    "\n",
    "    def forward(self, x: Dict):\n",
    "        # Using the encoder continuous which has the history window\n",
    "        x = x[\"encoder_cont\"] # x --> (batch_size, seq_len, input_size)\n",
    "        # Processing through the RNN\n",
    "        x, _ = self.rnn(x)  # --> (batch_size, seq_len, hidden_size)\n",
    "        # Using a FC layer on last hidden state\n",
    "        x = self.fc(x[:,-1,:])  # --> (batch_size, seq_len, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78844967-4e70-4bfa-8c8e-04fab02c33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    rnn_type=\"LSTM\",\n",
    "    input_size=len(training.reals),\n",
    "    hidden_size=256, #128\n",
    "    num_layers=2,\n",
    "    bidirectional=False,\n",
    ")\n",
    "other_params = dict(\n",
    "    learning_rate=5e-5,\n",
    "    optimizer=\"adam\",\n",
    "    loss=RMSE(),\n",
    "    logging_metrics=[RMSE(), MAE()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac78d1f-aa91-483f-9798-7d1d5f7f61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleStepRNNModel.from_dataset(\n",
    "    training,\n",
    "    network_callable=SimpleRNNModel,\n",
    "    model_params=model_params,\n",
    "    **other_params\n",
    ")\n",
    "#Testing out the model\n",
    "x, y = next(iter(train_dataloader))\n",
    "_ = model(x)\n",
    "type(_), _.prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a3169-f496-49f1-b258-3a619b5bcf5e",
   "metadata": {},
   "source": [
    "#### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83756e-bba0-4821-8582-c879c4eb8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_sampled = 'notebooks/Chapter14/saved_weights/baseline_sampled.wt'\n",
    "\n",
    "saved_model_full = 'notebooks/Chapter14/saved_weights/baseline.wt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fdfe8-9f40-4550-8849-e738e0e4ea31",
   "metadata": {},
   "source": [
    "### `WARNING`: Next block takes a very long time to run, possibly over `24 hours` on some machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa258af0-875c-4329-9938-9bf0d8c5f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        min_epochs=1,\n",
    "        max_epochs=20,\n",
    "        callbacks=[\n",
    "            pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3 if TRAIN_SUBSAMPLE else 4*3),\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor=\"val_loss\", save_last=True, mode=\"min\", auto_insert_metric_name=True\n",
    "            ),\n",
    "        ],\n",
    "        val_check_interval=1.0 if TRAIN_SUBSAMPLE else 2000,\n",
    "        log_every_n_steps=50 if TRAIN_SUBSAMPLE else 2000,\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    #Loading the best model\n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    best_model = SingleStepRNNModel.load_from_checkpoint(best_model_path)\n",
    "    print(f\"Loading the best model from: {best_model_path}\")\n",
    "    shutil.copy(best_model_path, saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full)\n",
    "else:\n",
    "    best_model_path = saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full\n",
    "    load_weights(model, best_model_path)\n",
    "    best_model =  model\n",
    "    print (\"Skipping Training and loading the model from {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e3fe9-beed-467f-b7b1-077410ab050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test dataset and storing in a df\n",
    "pred_output = best_model.predict(test, return_index=True, trainer_kwargs=dict(enable_progress_bar=True))\n",
    "pred, index = pred_output.output.cpu().numpy(), pred_output.index\n",
    "index[tag] = pred\n",
    "pred_df = pred_df.reset_index().merge(index, on=[\"time_idx\",\"LCLid\"], how='left').set_index(feat_config.index_cols)\n",
    "# Evaluating the forecast\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    pred_df = pred_df,\n",
    "    train_data = full_df,\n",
    "    fc_column=tag,\n",
    "    name=tag,\n",
    ")\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[tag]=eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852adbdd-c197-4f75-827a-3e602f879799",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4131a38-5882-4954-ad32-68337b273c72",
   "metadata": {},
   "source": [
    "### Baseline + Time-varying Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95ff73-a197-467c-948c-52d4d2b9682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"simple+time_varying\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bfee2-8e97-41f4-a8e7-8504b24993d7",
   "metadata": {},
   "source": [
    "#### Converting data into `TimeSeriesDataset` from PyTorch Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c0cc1-6568-400e-80d1-8b1b4b720d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training dataset\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=feat_config.target,\n",
    "    group_ids=feat_config.group_ids,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=feat_config.time_varying_known_reals,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"energy_consumption\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=feat_config.group_ids, transformation=None\n",
    "    )\n",
    ")\n",
    "# Defining the validation dataset with the same parameters as training\n",
    "validation = TimeSeriesDataSet.from_dataset(training, pd.concat([val_history,val_df]).reset_index(drop=True), stop_randomization=True)\n",
    "\n",
    "# Defining the test dataset with the same parameters as training\n",
    "test = TimeSeriesDataSet.from_dataset(training, pd.concat([hist_df, test_df]).reset_index(drop=True), stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c2f13-e643-49dd-b430-14e184bd6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the dataloaders\n",
    "# num_workers can be increased in linux to speed-up training\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fea3df-f7e0-4a6f-ab29-b9146df3b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the dataloader\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")\n",
    "print(\"\\nsize of y =\")\n",
    "print(f\"\\ty = {y[0].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938cccb-9048-4f1b-a0b3-13e0a2524ce3",
   "metadata": {},
   "source": [
    "#### Creating the Model\n",
    "\n",
    "##### [Additional] Rolling the input and formatting the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b53bf-2f85-4cc5-a803-7969bc2bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the encoder and decoder series\n",
    "x_cont = torch.cat([x[\"encoder_cont\"],x[\"decoder_cont\"]], dim=1)\n",
    "x_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adf974-76f1-459b-96f5-b8b4dea1cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the first batch target is\n",
    "x_cont[0,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb4dc7-3953-4c0e-887d-4fbf1f3c98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling the target by one step\n",
    "x_cont[:,:,-1] = torch.roll(x_cont[:,:,-1], 1, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5397895-7c49-4f56-b8e3-dbd42e6da6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the first batch target again.\n",
    "x_cont[0,:,-1]\n",
    "# We can see that it has shifted to the right by one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1326bd2-640f-4bba-ac0e-e6f9b82beeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1061f9e-3440-40f1-b75c-7cb3dc68f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the first timestep\n",
    "x_cont[0,1:,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52420e0a-70df-4673-809b-fe0b293e82e3",
   "metadata": {},
   "source": [
    "#### Defining The Forward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c172c6f-9fb1-4e29-b59d-e78c0672cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class DynamicFeatureRNNModel(SingleStepRNN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type: str,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "    ):\n",
    "        super().__init__(rnn_type, input_size, hidden_size, num_layers, bidirectional)\n",
    "\n",
    "    def forward(self, x: Dict):\n",
    "        # Using the encoder and decoder sequence (explanation in the book)\n",
    "        x_cont = torch.cat([x[\"encoder_cont\"],x[\"decoder_cont\"]], dim=1)\n",
    "        # Roll target by 1 (explanation in the book)\n",
    "        x_cont[:,:,-1] = torch.roll(x_cont[:,:,-1], 1, dims=1)\n",
    "        x = x_cont\n",
    "        # dropping first timestep (explanation in the book)\n",
    "        x = x[:,1:,:] # x --> (batch_size, seq_len, input_size)\n",
    "        # Processing through the RNN\n",
    "        x, _ = self.rnn(x)  # --> (batch_size, seq_len, hidden_size)\n",
    "        # Using a FC layer on last hidden state\n",
    "        x = self.fc(x[:,-1,:])  # --> (batch_size, seq_len, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5e62a-553d-4fa4-8827-92d1b9787d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    rnn_type=\"LSTM\",\n",
    "    input_size=len(training.reals),\n",
    "    hidden_size=256, #128\n",
    "    num_layers=2,\n",
    "    bidirectional=False,\n",
    ")\n",
    "\n",
    "other_params = dict(\n",
    "    learning_rate=5e-5,\n",
    "    optimizer=\"adam\",\n",
    "    loss=RMSE(),\n",
    "    logging_metrics=[RMSE(), MAE()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7254a-b6da-42d1-b5d3-46e56267b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleStepRNNModel.from_dataset(\n",
    "    training,\n",
    "    network_callable=DynamicFeatureRNNModel,\n",
    "    model_params = model_params,\n",
    "    **other_params\n",
    ")\n",
    "#Testing out the model\n",
    "x, y = next(iter(train_dataloader))\n",
    "_ = model(x)\n",
    "type(_), _.prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6380db-aa7a-4f01-b49b-04a14bf863c9",
   "metadata": {},
   "source": [
    "#### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee53e96-0b59-4b42-a724-6c12006c0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_sampled = 'notebooks/Chapter14/saved_weights/baseline_time_varying_sampled.wt'\n",
    "\n",
    "saved_model_full = 'notebooks/Chapter14/saved_weights/baseline_time_varying.wt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f300f1-96d8-4083-9c97-7785813b2307",
   "metadata": {},
   "source": [
    "##### Warning - Next block can take mant hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275250f-9a45-4cf8-8cae-775ba415ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        min_epochs=1,\n",
    "        max_epochs=20,\n",
    "        callbacks=[\n",
    "            pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3 if TRAIN_SUBSAMPLE else 4*3),\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor=\"val_loss\", save_last=True, mode=\"min\", auto_insert_metric_name=True\n",
    "            ),\n",
    "        ],\n",
    "        val_check_interval=1.0 if TRAIN_SUBSAMPLE else 2000,\n",
    "        log_every_n_steps=50 if TRAIN_SUBSAMPLE else 2000,\n",
    "        # fast_dev_run=True\n",
    "        # precision = 16\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    #Loading the best model\n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    best_model = SingleStepRNNModel.load_from_checkpoint(best_model_path)\n",
    "    print(f\"Loading the best model from: {best_model_path}\")\n",
    "    shutil.copy(best_model_path, saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full)\n",
    "else:\n",
    "    best_model_path = saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full\n",
    "    load_weights(model, best_model_path)\n",
    "    best_model =  model\n",
    "    print (\"Skipping Training and loading the model from {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53df968-0606-44fa-bfb0-e3a2259a482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test dataset and storing in a df\n",
    "pred_output = best_model.predict(test, return_index=True, trainer_kwargs=dict(enable_progress_bar=True))\n",
    "pred, index = pred_output.output.cpu().numpy(), pred_output.index\n",
    "index[tag] = pred\n",
    "pred_df = pred_df.reset_index().merge(index, on=[\"time_idx\",\"LCLid\"], how='left').set_index(feat_config.index_cols)\n",
    "\n",
    "# Evaluating the forecast\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    pred_df = pred_df,\n",
    "    train_data = full_df,\n",
    "    fc_column=tag,\n",
    "    name=tag,\n",
    ")\n",
    "\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[tag]=eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129e457-4cd1-44c8-b17f-adbec2287833",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record).style.format(\n",
    "    {\"MAE\": \"{:.4f}\", \"MSE\": \"{:.4f}\", \"meanMASE\": \"{:.4f}\", \"Forecast Bias\": \"{:.2f}%\"}\n",
    ").highlight_min(color=\"lightgreen\", subset=[\"MAE\", \"MSE\", \"meanMASE\"]).apply(\n",
    "    highlight_abs_min,\n",
    "    props=\"color:black;background-color:lightgreen\",\n",
    "    axis=0,\n",
    "    subset=[\"Forecast Bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d59ef8-89c8-4d6b-8e8a-bf68610163e8",
   "metadata": {},
   "source": [
    "### Baseline + Static + Time-varying Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a6dfc-a61a-4439-9d6e-6b1f1b309d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4530e-3d59-4ce9-95dd-aa9a352146f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791f190-f451-4881-aebd-8ea2f612176e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f63bc2-1deb-44e7-a4c6-e70e881fe09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03768b-9a15-4d9c-9f14-b2def516c632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc620470-96f9-49e4-881f-4bc8356a2b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7cb69-d04b-40bc-a186-54071c9dfdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fc5b5-c3c5-41ba-a9e2-8439637c994f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408cdbc6-c97c-46b3-820e-636a8cf999aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ad990-3641-40be-8f9e-35c5abd74ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175bb95-3ecb-48c0-a10d-eb546a872fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb3908-1b7c-420f-8516-5829fda0fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07451737-6c9c-4243-809a-67ee85c2dc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3af018-fc09-45f0-8eca-60859ae0b7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a99bc-68e2-464e-ac0f-88a187418c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40169aa-db88-4948-a8e7-2b72b74a9ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837f449-70a3-4989-ac0d-901e126fee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba265e21-9d86-42c2-a82e-44c134e7565a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c056bff-b872-416f-b438-2f9a21283252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4695e-bb7f-4cc8-ae82-1cdb5f6d394c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bf6e0-4d77-47ff-b24b-bbe14254b4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
