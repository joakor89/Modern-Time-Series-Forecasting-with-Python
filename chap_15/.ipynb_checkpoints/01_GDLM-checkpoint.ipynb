{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3af99f-8529-42fd-8801-9387710e4f51",
   "metadata": {},
   "source": [
    "# Global Deep Learning Models\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163b0db0-82c2-43d5-9e9b-340f1675b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0346-8f7e-4cb5-aa30-5aef750f8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# OS \n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython & Itertools\n",
    "from itertools import cycle\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa3115-1d77-4721-9618-cd8f528ca098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils import ts_utils_updated\n",
    "from src.forecasting.ml_forecasting import calculate_metrics\n",
    "\n",
    "from src.forecasting.ml_forecasting import (\n",
    "    MissingValueConfig,\n",
    "    calculate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29612068-6707-4291-814a-6ddf2a58f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53974cb4-26ce-4fe6-96d0-c2ba791e7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f48c6-54db-43fc-80ed-fde4c231b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_15\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8f0f9-da46-42a7-9527-1aa83be0d844",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6365f-2868-41ae-88c4-4e886fe1f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486977b-4997-4291-9a26-da02c15e5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [\n",
    "        \"rgba(\" + \",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)]) + \",<alpha>)\"\n",
    "        for c in px.colors.qualitative.Plotly\n",
    "    ]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pred_df[mask].index,\n",
    "            y=pred_df[mask].energy_consumption,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=act_color.replace(\"<alpha>\", \"0.9\")),\n",
    "            name=\"Actual Consumption\",\n",
    "        )\n",
    "    )\n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pred_df[mask].index,\n",
    "                y=pred_df.loc[mask, col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dot\", color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                name=display_col,\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s.abs() == np.nanmin(np.abs(s.values)), props, '')\n",
    "\n",
    "def evaluate_forecast(pred_df, train_data, fc_column, name, target_name=\"energy_consumption\"):\n",
    "    metric_l = []\n",
    "    for _id in tqdm(pred_df.index.get_level_values(0).unique(), desc=\"Calculating metrics...\"):\n",
    "        target = pred_df.xs(_id)[[target_name]]\n",
    "        _y_pred = pred_df.xs(_id)[[fc_column]]\n",
    "        history = train_data.xs(_id)[[target_name]]\n",
    "        # display(history.tail())\n",
    "        # display(_y_pred.head())\n",
    "        # display(target.head())\n",
    "        metric_l.append(\n",
    "            calculate_metrics(target, _y_pred, name=name, y_train=history)\n",
    "        )\n",
    "    eval_metrics_df = pd.DataFrame(metric_l)\n",
    "    agg_metrics = {\n",
    "            \"Algorithm\": name,\n",
    "            \"MAE\": np.nanmean(np.abs(pred_df[fc_column]-pred_df[target_name])),\n",
    "            \"MSE\": np.nanmean(np.power(pred_df[fc_column]-pred_df[target_name], 2)),\n",
    "            \"meanMASE\": eval_metrics_df.loc[:, \"MASE\"].mean(),\n",
    "            \"Forecast Bias\": 100*(np.nansum(pred_df[fc_column])-np.nansum(pred_df[target_name]))/np.nansum(pred_df[target_name])\n",
    "    }\n",
    "    return agg_metrics, eval_metrics_df\n",
    "\n",
    "#from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "from lightning_fabric.utilities.cloud_io import _load as pl_load\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = pl_load(weight_path)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221ada8-f039-4b05-8ec8-7dc3cc00eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "FeatureConfig = namedtuple(\n",
    "    \"FeatureConfig\",\n",
    "    [\n",
    "        \"target\",\n",
    "        \"index_cols\",\n",
    "        \"static_categoricals\",\n",
    "        \"static_reals\",\n",
    "        \"time_varying_known_categoricals\",\n",
    "        \"time_varying_known_reals\",\n",
    "        \"time_varying_unknown_reals\",\n",
    "        \"group_ids\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad7fb0-b310-44f5-bb5a-9d62d110766c",
   "metadata": {},
   "source": [
    "#### Reading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42152f-6da5-48e6-b404-944202520667",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97441-f204-4b0c-a4d1-19f41b5c9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on smaller set of data for daster iteration.\n",
    "if TRAIN_SUBSAMPLE:\n",
    "    print(\"sub sampling\")\n",
    "    SAMPLE = 10\n",
    "    sampled_LCLids = pd.Series(train_df.LCLid.unique().remove_unused_categories().categories).sample(SAMPLE, random_state=99).tolist()\n",
    "    train_df = train_df.loc[train_df.LCLid.isin(sampled_LCLids)]\n",
    "    test_df = test_df.loc[test_df.LCLid.isin(sampled_LCLids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2fe16-0c8e-4d05-813d-8d1e50f3c516",
   "metadata": {},
   "source": [
    "### Defining The Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7307-3ee9-4b16-becf-04c764af7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    target=\"energy_consumption\",\n",
    "    index_cols=[\"LCLid\", \"timestamp\"],\n",
    "    static_categoricals=[\n",
    "        \"LCLid\",\n",
    "        \"stdorToU\",\n",
    "        \"Acorn\",\n",
    "        \"Acorn_grouped\",\n",
    "        \"file\",\n",
    "    ],  # Categoricals which does not change with time\n",
    "    static_reals=[],  # Reals which does not change with time\n",
    "    time_varying_known_categoricals=[  # Categoricals which change with time\n",
    "        \"holidays\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "    ],\n",
    "    time_varying_known_reals=[  # Reals which change with time\n",
    "        \"apparentTemperature\",\n",
    "    ],  \n",
    "    time_varying_unknown_reals=[  # Reals which change with time, but we don't have the future. Like the target\n",
    "        \"energy_consumption\"\n",
    "    ],  \n",
    "    group_ids=[  # Feature or list of features which uniquely identifies each entity\n",
    "        \"LCLid\"\n",
    "    ],  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d53410-4c42-45b7-b37a-6c4640eab853",
   "metadata": {},
   "source": [
    "#### Creating a Continuous Time Index for PyTorch Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58332bb8-c455-4cd6-ba0d-8636e827a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test with a flag\n",
    "train_df['train'] = True\n",
    "test_df['train'] = False\n",
    "data = pd.concat([train_df, test_df])\n",
    "del train_df, test_df\n",
    "\n",
    "# Adding the time index\n",
    "data['time_idx'] = data.timestamp.apply(lambda x: x.value)\n",
    "diff = data.iloc[1]['time_idx'] - data.iloc[0]['time_idx']\n",
    "data[\"_min_time_idx\"] = data.groupby(\"LCLid\", observed=True)['time_idx'].transform(\"min\")\n",
    "data['time_idx'] = ((data['time_idx']-data['_min_time_idx'])/diff).astype(int)\n",
    "data.drop(columns=\"_min_time_idx\", inplace=True)\n",
    "\n",
    "# separating to train and test\n",
    "train_df = data.loc[data.train]\n",
    "test_df = data.loc[~data.train]\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc43bfb-c4d8-4164-8ec4-78c5c356c142",
   "metadata": {},
   "source": [
    "#### Converting The Categoricals to Object `dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f8782-43e9-4218-9467-b7004c99e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")\n",
    "\n",
    "test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dcaaf-1833-492f-a454-1ac07e6b9a9b",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ec634-dc5a-4541-a44b-dc64adac0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values\n",
    "n = train_df.isna().any()\n",
    "n[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc9b4ad-33f5-4f55-aed3-d4f17a1f96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We aren't using any of these features. So let it be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f45d69-c24f-48bc-8326-0be25371877c",
   "metadata": {},
   "source": [
    "## Training Global Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83d307-d4c8-41f8-8c79-7a28b9eddb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import RMSE, MAE\n",
    "from pytorch_forecasting.data import GroupNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb20b4e-e692-4bde-a231-c85449a0fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e6802-122e-47c8-adb6-45b04afc7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# os.makedirs(\"lightning_logs\", exist_ok=True)\n",
    "# %tensorboard --logdir lightning_logs/\n",
    "\n",
    "# Or start the tensorboard in a separate command prompt/terminal using\n",
    "# tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cc1f3-3020-4833-888b-1d0abc4efccb",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c14c2-21ed-4d5f-8a91-bfc82a9521da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 1\n",
    "max_encoder_length = 48*2\n",
    "\n",
    "batch_size = 512  # set this to a value which your GPU can handle\n",
    "train_model = True # Set this to True to train model. Else will load saved models ! Warning! Training on full dataset takes 3-6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58faab70-c43d-4710-9f08-6505aa59e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record = []\n",
    "\n",
    "individual_metrics = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9d5da-64ed-4f4e-9bcb-5533bd9868af",
   "metadata": {},
   "source": [
    "#### Creating Dataframes for `Train, Val and Test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba17f4-2310-4332-bb41-970ba4979147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.timestamp.max(), test_df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c0f15-8d14-4cff-999f-3c53be75fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(2, \"D\")\n",
    "hist_df = train_df[train_df.timestamp>history_cutoff]\n",
    "\n",
    "print(f\"History Min: {hist_df.timestamp.min()} | Max: {hist_df.timestamp.max()} | Length: {len(hist_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2c719-1494-40e5-a13d-07b73894574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping 1 days aside as a validation set\n",
    "cutoff = train_df.timestamp.max() - pd.Timedelta(1, \"D\")\n",
    "\n",
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(3, \"D\")\n",
    "val_history = train_df[(train_df.timestamp>=history_cutoff)&(train_df.timestamp<=cutoff)].reset_index(drop=True)\n",
    "val_df = train_df[train_df.timestamp>cutoff].reset_index(drop=True)\n",
    "train_df = train_df[train_df.timestamp<=cutoff].reset_index(drop=True)\n",
    "print(\"Split Timestamps:\")\n",
    "print(f\"Train Max: {train_df.timestamp.max()} | Val History Min and Max: {val_history.timestamp.min(), val_history.timestamp.max()} | Val Min and Max: {val_df.timestamp.min(), val_df.timestamp.max()}\")\n",
    "print(f\"Val History Size: {len(val_history.timestamp.unique())} | Val Size: {len(val_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595d43a-7202-4e1f-8f59-cf28298a162a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97e21c-d6fb-42c5-a3ba-7226bd72ad75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89314c03-ebf0-4c3b-9890-cce3eb672557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb63b60-18d1-4488-b285-c5d6b79b22e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce204e0-b653-43d1-9551-3aa8e90daa93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab1df1-75ff-42fa-a072-d0ef74354cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca9bf9-c119-480c-8175-0e84ad78e982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f244e9a-7535-4f23-926d-aad7828c54ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3521c-476d-4f60-bd52-1f580b5442eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2a6bb-29da-436d-bd2c-a20c60cc7e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1798e0-469d-4977-908e-0628b070f2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da4851-52d7-40fa-91d8-9ff5cc81cc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78844967-4e70-4bfa-8c8e-04fab02c33ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac78d1f-aa91-483f-9798-7d1d5f7f61e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273322b2-e8c0-4f9a-87c3-974edf208029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83756e-bba0-4821-8582-c879c4eb8430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49be9e8-2aeb-47a4-95bb-0402846d917a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa258af0-875c-4329-9938-9bf0d8c5f884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e3fe9-beed-467f-b7b1-077410ab050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852adbdd-c197-4f75-827a-3e602f879799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2069dd4-00e2-431b-8d83-e758396682fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95ff73-a197-467c-948c-52d4d2b9682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a790c-b3ad-4c24-b893-853eb9380099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c0cc1-6568-400e-80d1-8b1b4b720d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c2f13-e643-49dd-b430-14e184bd6bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fea3df-f7e0-4a6f-ab29-b9146df3b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
