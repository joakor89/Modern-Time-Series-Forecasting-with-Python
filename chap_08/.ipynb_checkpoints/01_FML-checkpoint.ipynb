{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82bf22e-2cf4-483d-a3c9-60ec16d35d62",
   "metadata": {},
   "source": [
    "# Forecasting with Machine Learning\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628677dc-0243-49b4-81f7-b5f08aa7d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce214fce-27a8-4627-ae0c-81a2d3a9c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_list_like\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Warnings\n",
    "import joblib\n",
    "import warnings\n",
    "import humanize\n",
    "\n",
    "# IO & Requests\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# StatsModels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import MSTL , DecomposeResult\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import sys\n",
    "import pickleshare\n",
    "import missingno as msno\n",
    "from itertools import cycle\n",
    "from typing import List, Tuple\n",
    "\n",
    "# PyArrow\n",
    "import pyarrow as pa\n",
    "\n",
    "# FuncTools\n",
    "from functools import partial\n",
    "\n",
    "# Path & Notebook Optimizer\n",
    "from pathlib import Path\n",
    "import missingno as msno\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NIXTLA\n",
    "from statsforecast.core import StatsForecast\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "# Forecast\n",
    "# from datasetsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "# SRC\n",
    "from src.utils import plotting_utils\n",
    "from src.utils.general import LogTime\n",
    "from src.utils.data_utils import _get_32_bit_dtype \n",
    "from src.utils.ts_utils_updated import mae, mse, mase\n",
    "from src.utils.ts_utils_updated import forecast_bias, metrics_adapter, \n",
    "from src.transforms.target_transformations import AutoStationaryTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55772708-0524-40f1-bc8a-6cfe6836506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070be37-2888-4d59-a83b-0db9f9b0a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f2f31-72fe-4797-843b-28c1c65fb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_08\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065fd48e-4acf-4e71-af70-1ea2e93f5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "sys.path.append('/Users/joaquinromero/Desktop/MTSF') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332b2e6-d735-48cb-b6fd-3feafcf335c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.window_ops.rolling import (\n",
    "    seasonal_rolling_max,\n",
    "    seasonal_rolling_mean,\n",
    "    seasonal_rolling_min,\n",
    "    seasonal_rolling_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc4ee6-f430-4e1f-96fe-6d153b8ad21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb7836-e43c-4c67-9668-b8901be79015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading The Missing Value Imputed and Train/Test Split Data\n",
    "try:\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"block_0-7_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8405acd-392d-4cf3-bad9-4eee1be549ee",
   "metadata": {},
   "source": [
    "#### Loading `The Single-Step Backtesting Baselines` for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc147eca-3aba-40cd-ae55-11cd4bc51cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the missing Value Imputed and Train/Test Split Data\n",
    "try:\n",
    "    baseline_metrics_df = pd.read_pickle(output/\"single_step_backtesting_baseline_metrics_val_df.pkl\")\n",
    "    baseline_aggregate_metrics_df = pd.read_pickle(output/\"single_step_backtesting_baseline_aggregate_metrics_val.pkl\")\n",
    "    # baseline_metrics_test_df = pd.read_pickle(output/\"single_step_backtesting_baseline_metrics_test_df.pkl\")\n",
    "    # baseline_aggregate_metrics_test_df = pd.read_pickle(output/\"single_step_backtesting_baseline_aggregate_metrics_test.pkl\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 00-Single Step Backtesting Baselines.ipynb in Chapter08\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4bc38-1edb-4d9e-955c-14e998615f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df.LCLid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13abf6-0f10-4e8d-ab90-4567fdc8d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676bfec-7cb3-4491-a142-463bdd07c20a",
   "metadata": {},
   "source": [
    "### Feature Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3ff08-f097-4513-aa69-781d0347d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    date=\"timestamp\",\n",
    "    target=\"energy_consumption\",\n",
    "    continuous_features=[\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma_span_2880\",\n",
    "        \"energy_consumption_ewma_span_336\",\n",
    "        \"energy_consumption_ewma_span_48\",\n",
    "        \"timestamp_Elapsed\",\n",
    "        \"timestamp_Month_sin_1\",\n",
    "        \"timestamp_Month_sin_2\",\n",
    "        \"timestamp_Month_sin_3\",\n",
    "        \"timestamp_Month_sin_4\",\n",
    "        \"timestamp_Month_sin_5\",\n",
    "        \"timestamp_Month_cos_1\",\n",
    "        \"timestamp_Month_cos_2\",\n",
    "        \"timestamp_Month_cos_3\",\n",
    "        \"timestamp_Month_cos_4\",\n",
    "        \"timestamp_Month_cos_5\",\n",
    "        \"timestamp_Hour_sin_1\",\n",
    "        \"timestamp_Hour_sin_2\",\n",
    "        \"timestamp_Hour_sin_3\",\n",
    "        \"timestamp_Hour_sin_4\",\n",
    "        \"timestamp_Hour_sin_5\",\n",
    "        \"timestamp_Hour_cos_1\",\n",
    "        \"timestamp_Hour_cos_2\",\n",
    "        \"timestamp_Hour_cos_3\",\n",
    "        \"timestamp_Hour_cos_4\",\n",
    "        \"timestamp_Hour_cos_5\",\n",
    "        \"timestamp_Minute_sin_1\",\n",
    "        \"timestamp_Minute_sin_2\",\n",
    "        \"timestamp_Minute_sin_3\",\n",
    "        \"timestamp_Minute_sin_4\",\n",
    "        \"timestamp_Minute_sin_5\",\n",
    "        \"timestamp_Minute_cos_1\",\n",
    "        \"timestamp_Minute_cos_2\",\n",
    "        \"timestamp_Minute_cos_3\",\n",
    "        \"timestamp_Minute_cos_4\",\n",
    "        \"timestamp_Minute_cos_5\",\n",
    "    ],\n",
    "    categorical_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"timestamp_Month\",\n",
    "        \"timestamp_Quarter\",\n",
    "        \"timestamp_WeekDay\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "        \"timestamp_Dayofyear\",\n",
    "        \"timestamp_Hour\",\n",
    "        \"timestamp_Minute\",\n",
    "    ],\n",
    "    boolean_features=[\n",
    "        \"timestamp_Is_quarter_end\",\n",
    "        \"timestamp_Is_quarter_start\",\n",
    "        \"timestamp_Is_year_end\",\n",
    "        \"timestamp_Is_year_start\",\n",
    "        \"timestamp_Is_month_start\",\n",
    "    ],\n",
    "    index_cols=[\"timestamp\"],\n",
    "    exogenous_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61712b-a608-4a19-9c40-b03ef1ac589d",
   "metadata": {},
   "source": [
    "### Sample Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0b3fe-9fc5-451f-bb99-563a342715ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_df = train_df.loc[train_df.LCLid == \"MAC000193\", :]\n",
    "sample_test_df = test_df.loc[test_df.LCLid == \"MAC000193\", :]\n",
    "train_features, train_target, train_original_target = feat_config.get_X_y(\n",
    "    sample_train_df, categorical=False, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = feat_config.get_X_y(\n",
    "    sample_test_df, categorical=False, exogenous=False\n",
    ")\n",
    "del sample_train_df, sample_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8905c6-a469-4f56-8401-8aaff2b27bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Missing Value Handling\n",
    "\n",
    "#### Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53028fa-f10b-4d9b-ab9f-bd65c365236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = train_features.isnull().sum()\n",
    "nc[nc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776ccd5-2781-457f-a074-33024aa855b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = test_features.isnull().sum()\n",
    "nc[nc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed633d5-ed51-4503-b0cb-4f4f713bc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_config = MissingValueConfig(\n",
    "    bfill_columns=[\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma__span_2880\",\n",
    "        \"energy_consumption_ewma__span_336\",\n",
    "        \"energy_consumption_ewma__span_48\",\n",
    "    ],\n",
    "    ffill_columns=[],\n",
    "    zero_fill_columns=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572746a4-d792-4d71-b24a-d8a2e58994ce",
   "metadata": {},
   "source": [
    "### Running ML Models on a Sample Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb2236-9a32-4f9f-9276-0bd8422a6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat([train_target, test_target])\n",
    "metric_record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be4bfa-b93b-400e-92f8-7e8ea06c3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record += (\n",
    "    baseline_metrics_df.loc[baseline_metrics_df.LCLid == \"MAC000193\"]\n",
    "    .drop(columns=\"LCLid\")\n",
    "    .to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9e06a-0b0b-4e13-8c2b-bbaf46b05857",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b87a9-93d2-49ca-be1f-311408620a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional, Tuple, Union, Sequence, Callable, cast\n",
    "# from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "# def is_datetime_dtypes(x):\n",
    "#     return is_datetime(x)\n",
    "\n",
    "# def cast_to_series(df):\n",
    "#     is_pd_dataframe = isinstance(df, pd.DataFrame)    \n",
    "#     if is_pd_dataframe: \n",
    "#         if df.shape[1]==1:\n",
    "#             df = df.squeeze()\n",
    "#         else:\n",
    "#             raise ValueError(\"Dataframes with more than one columns cannot be converted to pd.Series\")\n",
    "#     return df\n",
    "\n",
    "# def metrics_adapter(metric_func, actual_series,\n",
    "#         pred_series,\n",
    "#         insample = None,\n",
    "#         m: Optional[int] = 1,\n",
    "#         intersect: bool = True,\n",
    "#         reduction: Callable[[np.ndarray], float] = np.mean,\n",
    "#         inter_reduction: Callable[[np.ndarray], Union[float, np.ndarray]] = lambda x: x,\n",
    "#         n_jobs: int = 1,\n",
    "#         verbose: bool = False):\n",
    "    \n",
    "#     actual_series, pred_series = cast_to_series(actual_series), cast_to_series(pred_series)\n",
    "#     if insample is not None:\n",
    "#         insample = cast_to_series(insample)\n",
    "#     assert type(actual_series) is type(pred_series), f\"actual_series({type(actual_series)}) and pred_series({type(pred_series)}) should be of same type.\"\n",
    "#     if insample is not None:\n",
    "#         assert type(actual_series) is type(insample), \"actual_series and insample should be of same type.\"\n",
    "#     is_nd_array = isinstance(actual_series, np.ndarray)\n",
    "#     is_pd_series = isinstance(actual_series, pd.Series)\n",
    "    \n",
    "#     if is_pd_series:\n",
    "#         is_datetime_index = is_datetime_dtypes(actual_series.index) and is_datetime_dtypes(pred_series.index)\n",
    "#         if insample is not None:\n",
    "#             is_datetime_index = is_datetime_index and is_datetime_dtypes(insample.index)\n",
    "#     else:\n",
    "#         is_datetime_index = False\n",
    "#     if metric_func.__name__ == \"mase\":\n",
    "#         if not is_datetime_index:\n",
    "#             raise ValueError(\"MASE needs pandas Series with datetime index as inputs\")\n",
    "    \n",
    "#     # if is_nd_array or (is_pd_series and not is_datetime_index):\n",
    "#     #     actual_series, pred_series = TimeSeries.from_values(actual_series.values if is_pd_series else actual_series), TimeSeries.from_values(pred_series.values if is_pd_series else pred_series)\n",
    "#     #     if insample is not None:\n",
    "#     #         insample = TimeSeries.from_values(insample.values if is_pd_series else insample)\n",
    "\n",
    "#     # elif is_pd_series and is_datetime_index:\n",
    "#     #     actual_series, pred_series = TimeSeries.from_series(actual_series), TimeSeries.from_series(pred_series)\n",
    "#     #     if insample is not None:\n",
    "#     #         insample = TimeSeries.from_series(insample)\n",
    "#     # else:\n",
    "#     #     raise ValueError()\n",
    "#     if metric_func.__name__ == \"mase\":\n",
    "#         #return metric_func(actual_series=actual_series, pred_series=pred_series, insample=insample, m=m, intersect=intersect, reduction=reduction, inter_reduction=inter_reduction, n_jobs=n_jobs, verbose=verbose)\n",
    "#         return metric_func(actual_series, pred_series, insample)\n",
    "\n",
    "#     else:\n",
    "#         #return metric_func(actual_series=actual_series, pred_series=pred_series, intersect=intersect, reduction=reduction, inter_reduction=inter_reduction, n_jobs=n_jobs, verbose=verbose)\n",
    "#         return metric_func(actual_series, pred_series)\n",
    "\n",
    "\n",
    "# def calculate_metrics(\n",
    "#     y: pd.Series, y_pred: pd.Series, name: str, y_train: pd.Series = None\n",
    "# ):\n",
    "#     \"\"\"Method to calculate the metrics given the actual and predicted series\n",
    "\n",
    "#     Args:\n",
    "#         y (pd.Series): Actual target with datetime index\n",
    "#         y_pred (pd.Series): Predictions with datetime index\n",
    "#         name (str): Name or identification for the model\n",
    "#         y_train (pd.Series, optional): Actual train target to calculate MASE with datetime index. Defaults to None.\n",
    "\n",
    "#     Returns:\n",
    "#         Dict: Dictionary with MAE, MSE, MASE, and Forecast Bias\n",
    "#     \"\"\"\n",
    "#     return {\n",
    "#         \"Algorithm\": name,\n",
    "#         \"MAE\": darts_metrics_adapter(mae, actual_series=y, pred_series=y_pred),\n",
    "#         \"MSE\": darts_metrics_adapter(mse, actual_series=y, pred_series=y_pred),\n",
    "#         \"MASE\": darts_metrics_adapter(\n",
    "#             mase, actual_series=y, pred_series=y_pred, insample=y_train\n",
    "#         )\n",
    "#         if y_train is not None\n",
    "#         else None,\n",
    "#         \"Forecast Bias\": darts_metrics_adapter(\n",
    "#             forecast_bias, actual_series=y, pred_series=y_pred\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "\n",
    "# def mae(actuals, predictions):\n",
    "#     return np.nanmean(np.abs(actuals-predictions))\n",
    "\n",
    "# def mse(actuals, predictions):\n",
    "#     return np.nanmean(np.power(actuals-predictions, 2))\n",
    "\n",
    "# def mase(actuals, predictions, insample):\n",
    "#     \"\"\"\n",
    "#     Calculate the Mean Absolute Scaled Error (MASE).\n",
    "    \n",
    "#     Parameters:\n",
    "#     actuals : np.ndarray\n",
    "#         Actual observed values corresponding to the predictions.\n",
    "#     predictions : np.ndarray\n",
    "#         Predicted values.\n",
    "#     insample : np.ndarray\n",
    "#         In-sample data to calculate the scaling factor based on a naive forecast.\n",
    "\n",
    "#     Returns:\n",
    "#     float\n",
    "#         The MASE metric.\n",
    "#     \"\"\"\n",
    "#     # Calculate MAE of predictions\n",
    "#     mae_predictions = np.nanmean(np.abs(actuals - predictions))\n",
    "    \n",
    "#     # Shift the insample data to create a simple naive forecast\n",
    "#     naive_forecast = np.roll(insample, 1)\n",
    "#     # Assuming the first element is not a valid forecast\n",
    "#     naive_forecast[0] = np.nan \n",
    "    \n",
    "#     # Calculate MAE of the naive forecast\n",
    "#     mae_naive = np.nanmean(np.abs(insample - naive_forecast))\n",
    "    \n",
    "#     # Calculate MASE\n",
    "#     mase_value = mae_predictions / mae_naive\n",
    "#     return mase_value\n",
    "\n",
    "\n",
    "# def _remove_nan_union(array_a: np.ndarray,\n",
    "#                       array_b: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Returns the two inputs arrays where all elements are deleted that have an index that corresponds to\n",
    "#     a NaN value in either of the two input arrays.\n",
    "#     \"\"\"\n",
    "\n",
    "#     isnan_mask = np.logical_or(np.isnan(array_a), np.isnan(array_b))\n",
    "#     return np.delete(array_a, isnan_mask), np.delete(array_b, isnan_mask)\n",
    "\n",
    "# def forecast_bias(actual_series: Union[ np.ndarray],\n",
    "#         pred_series: Union[ np.ndarray],\n",
    "#         intersect: bool = True,\n",
    "#         *,\n",
    "#         reduction: Callable[[np.ndarray], float] = np.mean,\n",
    "#         inter_reduction: Callable[[np.ndarray], Union[float, np.ndarray]] = lambda x: x,\n",
    "#         n_jobs: int = 1,\n",
    "#         verbose: bool = False) -> Union[float, np.ndarray]:\n",
    "#     \"\"\" Forecast Bias (FB).\n",
    "\n",
    "#     Given a time series of actual values :math:`y_t` and a time series of predicted values :math:`\\\\hat{y}_t`\n",
    "#     both of length :math:`T`, it is a percentage value computed as\n",
    "\n",
    "#     .. math:: 100 \\\\cdot \\\\frac{\\\\sum_{t=1}^{T}{y_t}\n",
    "#               - \\\\sum_{t=1}^{T}{\\\\hat{y}_t}}{\\\\sum_{t=1}^{T}{y_t}}.\n",
    "\n",
    "#     If any of the series is stochastic (containing several samples), the median sample value is considered.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     actual_series\n",
    "#         The `TimeSeries` or `Sequence[TimeSeries]` of actual values.\n",
    "#     pred_series\n",
    "#         The `TimeSeries` or `Sequence[TimeSeries]` of predicted values.\n",
    "#     intersect\n",
    "#         For time series that are overlapping in time without having the same time index, setting `intersect=True`\n",
    "#         will consider the values only over their common time interval (intersection in time).\n",
    "#     reduction\n",
    "#         Function taking as input a `np.ndarray` and returning a scalar value. This function is used to aggregate\n",
    "#         the metrics of different components in case of multivariate `TimeSeries` instances.\n",
    "#     inter_reduction\n",
    "#         Function taking as input a `np.ndarray` and returning either a scalar value or a `np.ndarray`.\n",
    "#         This function can be used to aggregate the metrics of different series in case the metric is evaluated on a\n",
    "#         `Sequence[TimeSeries]`. Defaults to the identity function, which returns the pairwise metrics for each pair\n",
    "#         of `TimeSeries` received in input. Example: `inter_reduction=np.mean`, will return the average of the pairwise\n",
    "#         metrics.\n",
    "#     n_jobs\n",
    "#         The number of jobs to run in parallel. Parallel jobs are created only when a `Sequence[TimeSeries]` is\n",
    "#         passed as input, parallelising operations regarding different `TimeSeries`. Defaults to `1`\n",
    "#         (sequential). Setting the parameter to `-1` means using all the available processors.\n",
    "#     verbose\n",
    "#         Optionally, whether to print operations progress\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     ValueError\n",
    "#         If :math:`\\\\sum_{t=1}^{T}{y_t} = 0`.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         The Forecast Bias (OPE)\n",
    "#     \"\"\"\n",
    "#     assert type(actual_series) is type(pred_series), \"actual_series and pred_series should be of same type.\"\n",
    "#     if isinstance(actual_series, np.ndarray):\n",
    "#         y_true, y_pred = actual_series, pred_series\n",
    "#     else:\n",
    "#         y_true = actual_series\n",
    "#         y_pred = pred_series\n",
    "#     #     y_true, y_pred = _get_values_or_raise(actual_series, pred_series, intersect)\n",
    "#     #y_true, y_pred = _remove_nan_union(y_true, y_pred)\n",
    "#     y_true_sum, y_pred_sum = np.sum(y_true), np.sum(y_pred)\n",
    "#     # raise_if_not(y_true_sum > 0, 'The series of actual value cannot sum to zero when computing OPE.', logger)\n",
    "#     return ((y_true_sum - y_pred_sum) / y_true_sum) * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d783027-143c-428e-98b0-6efcfe533361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model_config,\n",
    "    feature_config,\n",
    "    missing_config,\n",
    "    train_features,\n",
    "    train_target,\n",
    "    test_features,\n",
    "    test_target,\n",
    "):\n",
    "    ml_model = MLForecast(\n",
    "        model_config=model_config,\n",
    "        feature_config=feat_config,\n",
    "        missing_config=missing_value_config,\n",
    "    )\n",
    "    ml_model.fit(train_features, train_target)\n",
    "    y_pred = ml_model.predict(test_features)\n",
    "    feat_df = ml_model.feature_importance()\n",
    "    metrics = calculate_metrics(test_target, y_pred, model_config.name, train_target)\n",
    "    return y_pred,  metrics, feat_df \n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [\n",
    "        \"rgba(\" + \",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)]) + \",<alpha>)\"\n",
    "        for c in px.colors.qualitative.Plotly\n",
    "    ]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pred_df[mask].index,\n",
    "            y=pred_df[mask].energy_consumption,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=act_color.replace(\"<alpha>\", \"0.9\")),\n",
    "            name=\"Actual Consumption\",\n",
    "        )\n",
    "    )\n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pred_df[mask].index,\n",
    "                y=pred_df.loc[mask, col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dot\", color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                name=display_col,\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(np.abs(s.values)), props, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ddae8-1ec2-4208-a0a8-ab0ff60eabab",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "\n",
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be7f84-d6c2-4534-8011-e974493f7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=LinearRegression(),\n",
    "    name=\"Linear Regression\",\n",
    "    # LinearRegression is sensitive to normalized data\n",
    "    normalize=True,\n",
    "    # LinearRegression cannot handle missing values\n",
    "    fill_missing=True,\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df, = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35303e-da84-4704-8289-889beb18780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce2b11-b6ee-4d02-b009-cfbef5b992ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/lin_reg.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510566b-1bab-4d92-a896-01dd408ad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/lin_reg_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa10656-c67c-4a85-ab39-179de0a75baf",
   "metadata": {},
   "source": [
    "#### Ridge Regression (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a36d4-b132-423a-b414-8bffd2e4bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=RidgeCV(), \n",
    "    name=\"Ridge Regression\", \n",
    "    # RidgeCV is sensitive to normalized data\n",
    "    normalize=True, \n",
    "    # RidgeCV does not handle missing values\n",
    "    fill_missing=True\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred,   metrics, feat_df,= evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb80f3-65e2-49f7-b774-bc1b25acc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946bd25-cec5-4e88-903a-09b759ec6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/ridge_reg.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf1bf5-05b6-4bec-b142-70bf954ff34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/ridge_reg_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf25e0c-9fb6-49e5-af76-e885ed6b6116",
   "metadata": {},
   "source": [
    "#### Lasso Regression (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150b4c1-c6f2-4cf8-adf9-42966a35c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=LassoCV(), \n",
    "    name=\"Lasso Regression\", \n",
    "    # LassoCV is sensitive to normalized data\n",
    "    normalize=True, \n",
    "    # LassoCV does not handle missing values\n",
    "    fill_missing=True\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7dffb-1547-4b64-ae95-8afecb2ae187",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/lasso_reg.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3e0da-29b8-4212-aadd-49c13446644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/lasso_reg_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df194749-c867-45b7-b242-a309db0ad3fa",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5c3be-7afb-4311-8536-f46126d6757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=DecisionTreeRegressor(max_depth=4, random_state=42),\n",
    "    name=\"Decision Tree\",\n",
    "    # Decision Tree is not affected by normalization\n",
    "    normalize=False,\n",
    "    # Decision Tree in scikit-learn does not handle missing values\n",
    "    fill_missing=True,\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb453303-03cc-4135-9d88-92a52d1648a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/dtree.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61b303-5c70-4f8b-806f-963ac74b64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/dtree_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70596790-9715-44b5-8745-bf44522a320c",
   "metadata": {},
   "source": [
    "### Bagging & Boosting Trees\n",
    "\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85cee0-d5ab-466d-8ebf-f84400a45145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=RandomForestRegressor(random_state=42, max_depth=4),\n",
    "    name=\"Random Forest\",\n",
    "    # RandomForest is not affected by normalization\n",
    "    normalize=False,\n",
    "    # RandomForest in scikit-learn does not handle missing values\n",
    "    fill_missing=True,\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d815d0a-f6aa-4103-819e-4a0a2a422074",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/rf.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4c7b3-06da-452a-8b66-6546fd68b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/rf_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c1c21-1274-48fb-a1f7-bd9aab99be47",
   "metadata": {},
   "source": [
    "#### XGBoost Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6ae32-81fb-4fdd-8bc8-dbbbb8a764a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=XGBRFRegressor(random_state=42, max_depth=4),\n",
    "    name=\"XGB Random Forest\",\n",
    "    # XGBRF is not affected by normalization\n",
    "    normalize=False,\n",
    "    # XGBRF handles missing values\n",
    "    fill_missing=False,\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc6dd0-8f51-4cef-a44c-f8e4914f6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_08/xgbrf.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7836592-664a-45bb-9570-6c3aa65448d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_08/xgbrf_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc88a3-af6a-4530-a729-b482a87f9b92",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fe2d1-f113-4b54-9dc1-84e6c97f3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"LightGBM\",\n",
    "    # LightGBM is not affected by normalization\n",
    "    normalize=False,\n",
    "    # LightGBM handles missing values\n",
    "    fill_missing=False,\n",
    ")\n",
    "with LogTime() as timer:\n",
    "    y_pred, metrics, feat_df = evaluate_model(\n",
    "        model_config,\n",
    "        feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        test_target,\n",
    "    )\n",
    "metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(metrics)\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c0956-4cc4-498f-be96-d32123cfe6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[model_config.name], forecast_display_names=[model_config.name])\n",
    "fig = format_plot(fig, title=f\"{model_config.name}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_8/lgbm.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47d976-e079-4367-adf4-9dc9e293cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_8/lgbm_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efb90d-a4ae-4c5c-a94a-db594e7c1883",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2591f-3abc-487e-81b5-48e3f1d04f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = pd.DataFrame(metric_record).style.format({\"MAE\": \"{:.4f}\", \n",
    "                          \"MSE\": \"{:.4f}\", \n",
    "                          \"MASE\": \"{:.4f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"})\n",
    "formatted.highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"MASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ca4ca-a080-4ae1-9f96-ce2d5c85f6e9",
   "metadata": {},
   "source": [
    "### Running ML Forecast for All Consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5042d6-75f9-4104-87a0-733cfcc759ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcl_ids = sorted(train_df.LCLid.unique())\n",
    "models_to_run = [\n",
    "    ModelConfig(\n",
    "        model=LassoCV(), name=\"Lasso Regression\", normalize=True, fill_missing=True\n",
    "    ),\n",
    "    ModelConfig(\n",
    "        model=XGBRFRegressor(random_state=42, max_depth=4),\n",
    "        name=\"XGB Random Forest\",\n",
    "        normalize=False,\n",
    "        fill_missing=False,\n",
    "    ),\n",
    "    ModelConfig(\n",
    "        model=LGBMRegressor(random_state=42),\n",
    "        name=\"LightGBM\",\n",
    "        normalize=False,\n",
    "        fill_missing=False,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e75b6d-117a-49e3-9334-387f475d271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_metrics = []\n",
    "\n",
    "# We can parallelize this loop to run this faster\n",
    "with LogTime() as timer:\n",
    "    for lcl_id in tqdm(lcl_ids):\n",
    "        for model_config in models_to_run:\n",
    "            model_config = model_config.clone()\n",
    "            X_train, y_train, _ = feat_config.get_X_y(\n",
    "                train_df.loc[train_df.LCLid == lcl_id, :],\n",
    "                categorical=False,\n",
    "                exogenous=False,\n",
    "            )\n",
    "            X_test, y_test, _ = feat_config.get_X_y(\n",
    "                test_df.loc[test_df.LCLid == lcl_id, :], categorical=False, exogenous=False\n",
    "            )\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                y_pred, metrics, feat_df = evaluate_model(\n",
    "                    model_config,\n",
    "                    feat_config,\n",
    "                    missing_value_config,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                )\n",
    "            y_pred.name = \"predictions\"\n",
    "            y_pred = y_pred.to_frame()\n",
    "            y_pred[\"LCLid\"] = lcl_id\n",
    "            y_pred[\"Algorithm\"] = model_config.name\n",
    "            metrics[\"LCLid\"] = lcl_id\n",
    "            metrics[\"Algorithm\"] = model_config.name\n",
    "            y_pred[\"energy_consumption\"] = y_test.values\n",
    "            all_preds.append(y_pred)\n",
    "            all_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b85a5-f709-4150-b4a9-836b9c8ff998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat(all_preds)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eda990-2730-47c7-b674-aec970f40cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c15b06-66e7-48f6-9a84-75cf9b830ca3",
   "metadata": {},
   "source": [
    "### Evaluation of ML Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33f22f-753e-46bc-90db-3c5fb98049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ts_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc3b37-c006-4e2e-85e7-48726a8ccb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_aggregate_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22694a82-44d0-4e29-a640-c180231d1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = baseline_aggregate_metrics_df.reset_index().rename(columns={\"index\":\"Algorithm\"}).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409341ee-a536-42c6-84e0-e5f3a131ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_config in models_to_run:\n",
    "    pred_mask = pred_df.Algorithm==model_config.name\n",
    "    metric_mask = metrics_df.Algorithm==model_config.name\n",
    "    metrics.append({\n",
    "    \"Algorithm\": model_config.name,\n",
    "    \"MAE\": ts_utils.mae(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"MSE\": ts_utils.mse(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"meanMASE\": metrics_df.loc[metric_mask, \"MASE\"].mean(),\n",
    "    \"Forecast Bias\": ts_utils.forecast_bias_aggregate(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f778798-6eb9-4453-a09b-c18eb9fcf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics_df = pd.DataFrame(metrics)\n",
    "agg_metrics_df.style.format({\"MAE\": \"{:.4f}\", \n",
    "                          \"MSE\": \"{:.4f}\", \n",
    "                          \"meanMASE\": \"{:.4f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b5d76-0112-4dda-bfea-57f730d8c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MASE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MASE\", ylabel=\"Probability Density\", title=\"Distribution of MASE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,2.5])\n",
    "fig.write_image(\"imgs/chapter_08/mase_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255f35c-effd-4c81-b4b4-39b22732ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MAE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=100, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MAE\", ylabel=\"Probability Density\", title=\"Distribution of MAE in the dataset\")\n",
    "fig.write_image(\"imgs/chapter_08/mae_dist.png\")\n",
    "fig.update_layout(xaxis_range=[0,0.4])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521de429-081a-4d66-9753-b147fcef0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MSE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MSE\", ylabel=\"Probability Density\", title=\"Distribution of MSE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,0.3])\n",
    "fig.write_image(\"imgs/chapter_08/mse_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd304a41-0332-477a-9f3b-d389bcbe90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"Forecast Bias\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=250,\n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"Forecast Bias\", ylabel=\"Probability Density\", title=\"Distribution of Forecast Bias in the dataset\")\n",
    "fig.update_layout(xaxis_range=[-50,30])\n",
    "fig.write_image(\"imgs/chapter_08/bias_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40710f85-dbb2-4c07-950a-c126617db0e8",
   "metadata": {},
   "source": [
    "### Saving `The Baseline Forecasts and Metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca2c2c-8971-4dfa-bca7-fd5a3b37e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/london_smart_meters/output\", exist_ok=True)\n",
    "\n",
    "output = Path(\"data/london_smart_meters/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f504f7-ea55-4293-859a-770884cf7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_pickle(output/\"ml_single_step_prediction_val_df.pkl\")\n",
    "metrics_df.to_pickle(output/\"ml_single_step_metrics_val_df.pkl\")\n",
    "agg_metrics_df.to_pickle(output/\"ml_single_step_aggregate_metrics_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59726bd-b288-4db9-993f-3a721ec7760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bonus: `Using Exogenous Variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9bdce-0418-4b53-8894-5ba50382b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcl_ids = sorted(train_df.LCLid.unique())\n",
    "models_to_run = [\n",
    "    ModelConfig(model = LGBMRegressor(random_state=42), name=\"LightGBM\", normalize=False, fill_missing=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8d765-449d-4f8b-a54e-0375126e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import DataConversionWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e084c-f7e3-401a-ba69-3d9de1ceed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_metrics = []\n",
    "#We can parallelize this loop to run this faster\n",
    "for lcl_id in tqdm(lcl_ids):\n",
    "    for model_config in models_to_run:\n",
    "        model_config = model_config.clone()\n",
    "        X_train, y_train, _ = feat_config.get_X_y(train_df.loc[train_df.LCLid==lcl_id,:], categorical=False, exogenous=True)\n",
    "        X_test, y_test, _ = feat_config.get_X_y(test_df.loc[test_df.LCLid==lcl_id,:], categorical=False, exogenous=True)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # warnings.filterwarnings(\"ignore\",category=DataConversionWarning)\n",
    "            y_pred, metrics, feat_df = evaluate_model(model_config, feat_config, missing_value_config, X_train, y_train, X_test, y_test)\n",
    "        y_pred.name = \"predictions\"\n",
    "        y_pred = y_pred.to_frame()\n",
    "        y_pred['LCLid'] = lcl_id\n",
    "        y_pred['Algorithm'] = model_config.name+\"_w_exog\"\n",
    "        metrics[\"LCLid\"] = lcl_id\n",
    "        metrics[\"Algorithm\"] = model_config.name+\"_w_exog\"\n",
    "        y_pred['energy_consumption'] = y_test.values\n",
    "        all_preds.append(y_pred)\n",
    "        all_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6b6b6-919b-4b31-b786-f464fee4be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_w_ex_df = pd.concat(all_preds)\n",
    "pred_w_ex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568c3de-3afb-4271-9436-c0111695c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_w_ex_df = pd.DataFrame(all_metrics)\n",
    "metrics_w_ex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3b33e-a580-449d-99bb-1185b66c2e7e",
   "metadata": {},
   "source": [
    "### Evaluation of ML Forecast with Exogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db869b6-bf25-44f1-ac07-b5def30ab177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ts_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db125f-24fb-40bc-b6b3-8932346fc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = baseline_aggregate_metrics_df.reset_index().rename(columns={\"index\":\"Algorithm\"}).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0954dd-9448-4b6a-9669-19182ae6e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(agg_metrics_df.iloc[4].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7f72b-8694-4b3d-94fc-e5457a2d748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_config in models_to_run:\n",
    "    pred_mask = pred_w_ex_df.Algorithm==model_config.name+\"_w_exog\"\n",
    "    metric_mask = metrics_w_ex_df.Algorithm==model_config.name+\"_w_exog\"\n",
    "    metrics.append({\n",
    "    \"Algorithm\": model_config.name+\"_w_exog\",\n",
    "    \"MAE\": ts_utils.mae(pred_w_ex_df.loc[pred_mask,\"energy_consumption\"], pred_w_ex_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"MSE\": ts_utils.mse(pred_w_ex_df.loc[pred_mask,\"energy_consumption\"], pred_w_ex_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"meanMASE\": metrics_w_ex_df.loc[metric_mask, \"MASE\"].mean(),\n",
    "    \"Forecast Bias\": ts_utils.forecast_bias_aggregate(pred_w_ex_df.loc[pred_mask,\"energy_consumption\"], pred_w_ex_df.loc[pred_mask,\"predictions\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11b593-7172-404e-b532-10464af68316",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics_w_ex_df = pd.DataFrame(metrics)\n",
    "agg_metrics_w_ex_df.style.format({\"MAE\": \"{:.3f}\", \n",
    "                          \"MSE\": \"{:.3f}\", \n",
    "                          \"meanMASE\": \"{:.3f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85007b3e-3c10-4224-b9d7-309282cccaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
