{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d3eee4-6f6d-4861-b190-63a82ba60d66",
   "metadata": {},
   "source": [
    "# Self-Attention &b Multi-Head Attention\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8788baf6-2183-4c51-8839-23b4bde9913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd9838-f99a-4247-ae25-fa178f333d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# OS \n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython & Itertools\n",
    "from itertools import cycle\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da086dc-54fd-45b0-8447-0b0fadf20d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils import ts_utils_updated\n",
    "from src.forecasting.ml_forecasting import calculate_metrics\n",
    "\n",
    "from src.forecasting.ml_forecasting import (\n",
    "    MissingValueConfig,\n",
    "    calculate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa340caa-1d87-49e6-9e13-ee3872c65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f815614-a7a9-468a-affc-6f551afb3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3aef3-27d3-4bb0-b19e-3ebaf0679448",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_14\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac71b1-4490-44a2-8fe5-7c7629277dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.0,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77245e41-10b5-48aa-b685-0f90918aada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "\n",
    "attn_dim = 64\n",
    "\n",
    "seq_len = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c21331-194e-4be2-ab30-99599e44cbd7",
   "metadata": {},
   "source": [
    "### Embedding Representation of a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db310c67-4858-49a1-96d9-845fac366342",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = torch.randn(seq_len, embedding_dim)\n",
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c67f5-54a8-433b-9099-605ee9f4e2af",
   "metadata": {},
   "source": [
    "## Self Attention\n",
    "\n",
    "#### `Step 1`: Define three learnable matrices, one each for query, key, and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d713cd3-61aa-4b19-8f68-5fe77f812bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_q = torch.randn(embedding_dim, attn_dim)\n",
    "w_k = torch.randn(embedding_dim, attn_dim)\n",
    "w_v = torch.randn(embedding_dim, attn_dim)\n",
    "\n",
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    w_q\n",
    "    w_k\n",
    "    w_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc92b39-b776-4c8c-9681-1fe5b5f80b99",
   "metadata": {},
   "source": [
    "#### `Step 2`: Convert input embeding into attention dimensions using `W_q, W_k, W_v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3633833-15cb-4de0-bc42-d50266ce0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    q = sentence @ w_q\n",
    "    k = sentence @ w_k\n",
    "    v = sentence @ w_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30439a-ebf3-4cf9-8cd5-07cf3643e6c2",
   "metadata": {},
   "source": [
    "#### `Step 3`: Calculate the attention weights between all the query and value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a9d00-f58b-4545-afb9-9e08ebbfa5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 1/math.sqrt(attn_dim)\n",
    "\n",
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    attn_scores = q @ v.t()\n",
    "attn_weights = torch.softmax(attn_scores/scaling, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f738f-619c-4c41-9a13-702b0888ba66",
   "metadata": {},
   "source": [
    "#### `Step 4`: Use the attention weights to combine the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586dc0be-7ba1-4413-b1c7-f1b645537556",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    attn_output = attn_weights @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b63c2-872e-49c1-87fe-be78d2bc8957",
   "metadata": {},
   "source": [
    "#### Putting it All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6176f-3a59-44e3-b225-3dbf7babf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    sentence\n",
    "    w_q\n",
    "    w_k\n",
    "    w_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada535be-88a0-46d5-a69b-ef577318803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsensor.astviz(\"attn_output = ((sentence @ w_q) @ (sentence @ w_k).t()) @ (sentence @ w_v)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb2ef8-005e-4ed4-a398-7fa6fa5e35e8",
   "metadata": {},
   "source": [
    "## Multi-Headed Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af127035-036b-43e7-bee3-b302c1b72066",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31809c-6012-4c86-9879-e2bf5041ef22",
   "metadata": {},
   "source": [
    "#### `Step 1`: Define three learnable matrices, one each for query, key and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd1ea2-5754-40c3-b2bd-61a60711d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_q = torch.randn(embedding_dim, attn_dim)\n",
    "w_k = torch.randn(embedding_dim, attn_dim)\n",
    "w_v = torch.randn(embedding_dim, attn_dim)\n",
    "\n",
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    w_q\n",
    "    w_k\n",
    "    w_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ee5ac-a7a3-4ddd-b49c-b2a4dca94567",
   "metadata": {},
   "source": [
    "#### `Step 2`: Convert input embeding into attention dimensions using W_q, W_k, W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c1eac-5623-4859-a0a7-31d8c945c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    q = sentence @ w_q\n",
    "    k = sentence @ w_k\n",
    "    v = sentence @ w_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a7338-1ce5-4062-9f13-4e6f78d2f4f6",
   "metadata": {},
   "source": [
    "#### `Step 3`: Reshape q, k and v into sub_dim for each head in the multi-headed attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c89858-29cb-4aa2-ba7f-7352a179eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dim = attn_dim//n_heads\n",
    "with tsensor.explain(fontsize=20, dimfontsize=12):\n",
    "    q = q.reshape(seq_len, n_heads, sub_dim).permute(1,0,2)\n",
    "shape_str = \" x \".join([str(i) for i in q.size()])\n",
    "display(md(f\"\"\"\n",
    "-----\n",
    "### q, k, v dimensions: n_heads, seq_len, sub_dim : {shape_str}\n",
    "\"\"\"))\n",
    "#Similar transformation to k and v\n",
    "k = k.reshape(seq_len, n_heads, sub_dim).permute(1,0,2)\n",
    "v = v.reshape(seq_len, n_heads, sub_dim).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee6cfdb-4441-43ad-8549-a9686b991c80",
   "metadata": {},
   "source": [
    "##### `q, k, v` dimensions: n_heads, seq_len, sub_dim : `8 x 10 x 8`\n",
    "\n",
    "#### `Step 4`: Calculate the attention weights between all the query and value pairs for each head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868a32d-7268-4319-99aa-70215e1bb91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054226f7-5f79-4228-983d-213343e7e683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e12b52-b2c8-4426-8680-ee8275c98ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294f771-72bd-4390-b169-33405b8421e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285db474-88fe-4ca8-9501-a11ecf706faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b98a5e-fd40-4a5d-a6b6-dd7bda85ec0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b6028-b88a-490b-8cd3-2c66e17ed1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735001f-1a2a-4344-bb75-55d50f7fc091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337b5d6-4984-49d4-8614-18dd2428a966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cddfd5-3058-41f9-be7e-edb43425f967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81aca4-9070-4ca2-8773-5ddd16f170e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7c6ce-359e-4334-b7c8-583546dccd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454d5f0-2d3c-4cd9-84ff-442baf8d4055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c89b33-1fa3-44d2-8a1a-48d05a25be50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a380b-c499-465e-a555-e450ef7ae2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0995d-a860-4dda-854d-9ed01d082473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16075b-4755-4d17-9bd4-07d4fd36d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd098c62-544f-4636-989c-d7c896a65410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
