{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c915dc-a383-440c-938d-27cdc4540d4c",
   "metadata": {},
   "source": [
    "# Global Forecasting Models (ML) Test\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f9508-ec3b-444c-9c8b-31a5735c412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf709ebb-33e4-41fe-8231-34c4f918c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# OS & Time\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# Warnings, Func & Path\n",
    "import warnings\n",
    "import pickleshare\n",
    "import missingno as msno\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "\n",
    "# PyArrow\n",
    "import pyarrow as pa\n",
    "\n",
    "# Humanize\n",
    "import humanize\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython - Display\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Random\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c957a9-1257-4bcb-9275-1636666b00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils.general import LogTime\n",
    "from src.utils.data_utils import _get_32_bit_dtype \n",
    "from src.utils.ts_utils_updated import metrics_adapter, forecast_bias,mae, mase, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898beeb8-e8d3-4fad-8c5f-1f033449931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.forecasting.ml_forecasting import (\n",
    "    FeatureConfig,\n",
    "    MissingValueConfig,\n",
    "    MLForecast,\n",
    "    ModelConfig,\n",
    "    calculate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c895055-36ff-4901-b3c1-e029e9b9fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c6fe8-6815-46e5-937b-1560cb66be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1a92b-3a1c-47d3-acac-66c90f01c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_10\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5b784-f32e-44ea-8a8d-6e257cb757ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.9,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88e386-d589-4b65-8d36-b7718fbc5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    val_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "\n",
    "    # Combine train and val into new train\n",
    "    train_df = pd.concat([train_df, val_df])\n",
    "    del val_df\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b48187-3d67-4338-aa9a-e910353de6e4",
   "metadata": {},
   "source": [
    "#### Loading `The Single-Step Backtesting Baselines` for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71776848-74e1-4d3c-a87e-07a2bf9cd895",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    baseline_aggregate_metrics_df = pd.read_pickle(output/\"ml_single_step_aggregate_metrics_auto_stationary_test.pkl\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 02a-Forecasting with Target Transformation(Test).ipynb in Chapter08\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9447b-e9ac-4255-b771-e69abc9f71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df.LCLid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520046b-d69e-43ae-9475-a06d5af8323e",
   "metadata": {},
   "source": [
    "### Feature Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963aea31-982f-465e-a93d-be32d57c0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    date=\"timestamp\",\n",
    "    target=\"energy_consumption\",\n",
    "    continuous_features=[\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma_span_2880\",\n",
    "        \"energy_consumption_ewma_span_336\",\n",
    "        \"energy_consumption_ewma_span_48\",\n",
    "        \"timestamp_Elapsed\",\n",
    "        \"timestamp_Month_sin_1\",\n",
    "        \"timestamp_Month_sin_2\",\n",
    "        \"timestamp_Month_sin_3\",\n",
    "        \"timestamp_Month_sin_4\",\n",
    "        \"timestamp_Month_sin_5\",\n",
    "        \"timestamp_Month_cos_1\",\n",
    "        \"timestamp_Month_cos_2\",\n",
    "        \"timestamp_Month_cos_3\",\n",
    "        \"timestamp_Month_cos_4\",\n",
    "        \"timestamp_Month_cos_5\",\n",
    "        \"timestamp_Hour_sin_1\",\n",
    "        \"timestamp_Hour_sin_2\",\n",
    "        \"timestamp_Hour_sin_3\",\n",
    "        \"timestamp_Hour_sin_4\",\n",
    "        \"timestamp_Hour_sin_5\",\n",
    "        \"timestamp_Hour_cos_1\",\n",
    "        \"timestamp_Hour_cos_2\",\n",
    "        \"timestamp_Hour_cos_3\",\n",
    "        \"timestamp_Hour_cos_4\",\n",
    "        \"timestamp_Hour_cos_5\",\n",
    "        \"timestamp_Minute_sin_1\",\n",
    "        \"timestamp_Minute_sin_2\",\n",
    "        \"timestamp_Minute_sin_3\",\n",
    "        \"timestamp_Minute_sin_4\",\n",
    "        \"timestamp_Minute_sin_5\",\n",
    "        \"timestamp_Minute_cos_1\",\n",
    "        \"timestamp_Minute_cos_2\",\n",
    "        \"timestamp_Minute_cos_3\",\n",
    "        \"timestamp_Minute_cos_4\",\n",
    "        \"timestamp_Minute_cos_5\",\n",
    "    ],\n",
    "    categorical_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"timestamp_Month\",\n",
    "        \"timestamp_Quarter\",\n",
    "        \"timestamp_WeekDay\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "        \"timestamp_Dayofyear\",\n",
    "        \"timestamp_Hour\",\n",
    "        \"timestamp_Minute\"\n",
    "    ],\n",
    "    boolean_features=[\n",
    "        \"timestamp_Is_quarter_end\",\n",
    "        \"timestamp_Is_quarter_start\",\n",
    "        \"timestamp_Is_year_end\",\n",
    "        \"timestamp_Is_year_start\",\n",
    "        \"timestamp_Is_month_start\",\n",
    "    ],\n",
    "    index_cols=[\"LCLid\",\"timestamp\"],\n",
    "    exogenous_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf774771-25f1-4eb8-9bdb-89acb3e845b2",
   "metadata": {},
   "source": [
    "### Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9beb9af-6812-4284-bac8-1c3e51f0f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_config = MissingValueConfig(\n",
    "    bfill_columns=[\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma__span_2880\",\n",
    "        \"energy_consumption_ewma__span_336\",\n",
    "        \"energy_consumption_ewma__span_48\",\n",
    "    ],\n",
    "    ffill_columns=[],\n",
    "    zero_fill_columns=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd487c5-a628-4321-a42c-08912bc35b67",
   "metadata": {},
   "source": [
    "## Training Global ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d4177-6e0f-45e6-abd2-7aadc41a0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ts_utils_updated\n",
    "\n",
    "from src.forecasting.ml_forecasting import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa5f93-915a-44a7-81be-107745120d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model_config,\n",
    "    feature_config,\n",
    "    missing_config,\n",
    "    train_features,\n",
    "    train_target,\n",
    "    test_features,\n",
    "    fit_kwargs={}\n",
    "):\n",
    "    ml_model = MLForecast(\n",
    "        model_config=model_config,\n",
    "        feature_config=feature_config,\n",
    "        missing_config=missing_config,\n",
    "    )\n",
    "    ml_model.fit(train_features, train_target, fit_kwargs=fit_kwargs)\n",
    "    y_pred = ml_model.predict(test_features)\n",
    "    feat_df = ml_model.feature_importance()\n",
    "    return y_pred, feat_df\n",
    "\n",
    "def evaluate_forecast(y_pred, test_target, train_target, model_config):\n",
    "    metric_l = []\n",
    "    for _id in tqdm(test_target.index.get_level_values(0).remove_unused_categories().categories, desc=\"Calculating metrics...\"):\n",
    "        target = test_target.xs(_id)\n",
    "        _y_pred = y_pred.xs(_id)\n",
    "        history = train_target.xs(_id)\n",
    "        metric_l.append(\n",
    "            calculate_metrics(target, _y_pred, name=model_config.name, y_train=history)\n",
    "        )\n",
    "    eval_metrics_df = pd.DataFrame(metric_l)\n",
    "    agg_metrics = {\n",
    "            \"Algorithm\": model_config.name,\n",
    "            \"MAE\": ts_utils.mae(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ),\n",
    "            \"MSE\": ts_utils.mse(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ),\n",
    "            \"meanMASE\": eval_metrics_df.loc[:, \"MASE\"].mean(),\n",
    "            \"Forecast Bias\": ts_utils.forecast_bias_aggregate(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            )\n",
    "    }\n",
    "    return agg_metrics, eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f91625-d8da-47ab-87a5-65bbdf2c2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record = []\n",
    "individual_metrics = dict()\n",
    "\n",
    "metric_record = (\n",
    "    baseline_aggregate_metrics_df.iloc[[4]]\n",
    "    .to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ed5a1-68bc-4dda-b462-9e2d2df9073f",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7c595-b371-4110-9e5c-c965b3cbfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_feat_config = copy.deepcopy(feat_config)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "pred_df = test_target.copy()\n",
    "\n",
    "cat_features = set(train_features.columns).intersection(_feat_config.categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7f410-4e46-4436-be55-2ab880e4e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM Baseline\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98786b-2157-4da8-bb6f-761fb46b1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    y_pred, test_target, train_target, model_config\n",
    ")\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa259-f257-4afc-804a-af874915b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d78976-4f6b-4748-a96b-638426289e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/baseline_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6c456-49b3-4341-b46f-32783d42e327",
   "metadata": {},
   "source": [
    "### With Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b89ba-1454-4e19-a4b0-4b6a108b1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"Acorn_grouped\", \"LCLid\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "cat_features = set(train_features.columns).intersection(_feat_config.categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a29b4-14c5-4ffd-9b79-6642291a42ef",
   "metadata": {},
   "source": [
    "#### CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2874d-d4dc-49a0-897f-3df6cdd6a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import CountEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "cat_encoder = CountEncoder(cols=cat_features)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta (CountEncoder)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    "    encode_categorical=True,\n",
    "    categorical_encoder=cat_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf2f08-c5bf-43d8-860d-eb4da16417fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89af000-f879-4365-9022-f4c535659e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f0d30-d0e6-4638-943c-690d6ab9f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/baseline_w_meta_cnt_encoder_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8eed7-a31c-49a1-a949-027209ac1fe8",
   "metadata": {},
   "source": [
    "#### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83653612-7833-4d0c-8282-e9dc9cae4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "cat_encoder = TargetEncoder(cols=cat_features)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta  (TargetEncoder)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    "    encode_categorical=True,\n",
    "    categorical_encoder=cat_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1956e-5541-40b3-adae-66e3f03bc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de3b1f-fce7-4b93-8144-ef9f3276c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d30fa6-eaf4-4856-938f-aa45eedfd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/baseline_w_meta_tgt_encoder_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd78d1-dcaf-4aa5-ad2a-2509ab4f0204",
   "metadata": {},
   "source": [
    "#### Native LightGBM Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e3b39-1238-4f25-b590-af628bc48a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta  (NativeLGBM)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce68668-1e8f-42b4-bbcd-790d2d77b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features),\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34814fa-d46f-4b55-b530-0388d993e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a6f47-1ab9-445f-a30f-81aca8391f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/baseline_w_meta_native_lgbm_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56ed27-3782-4518-9d59-0b7ddb6d3c95",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849aeb17-d5a5-4f0d-bf7a-e3ffb3e9ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"Acorn_grouped\", \"LCLid\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "cat_features = set(train_features.columns).intersection(_feat_config.categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afe949-0a07-4ea0-acba-6e06c4be1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"num_leaves\": 99,\n",
    "    \"objective\": \"regression_l1\",\n",
    "    \"colsample_bytree\": 0.9786759775515064,\n",
    "    \"lambda_l1\": 8.160098582954642,\n",
    "    \"lambda_l2\": 0.17840888757497253,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d58562-b5d8-4d71-9fa2-53a65ff5d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params),\n",
    "    name=\"Tuned GFM+Meta\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16900551-ff3c-43e9-bb64-aae2de610aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features)\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c10d0-d830-4618-ac83-8c020f4e04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f822223-78e9-4d7a-b6d7-c7d71093190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/tuned_meta_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c4f3a-34ba-41d6-8e39-b47a2fd0bdf3",
   "metadata": {},
   "source": [
    "### Partitioning\n",
    "\n",
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4604604-38e8-42e5-99cf-ab80ba10f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"LCLid\", \"Acorn_grouped\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dab2e-036e-4aba-8040-2f6f1418df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params, verbose=-1),\n",
    "    name=\"Tuned GFM+Meta+Random Part\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c1377-ab1c-4f10-9f27-67d9f07bfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (list_in, n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "partitions = partition(train_df.LCLid.cat.categories.tolist(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4826a7-6a57-4d28-a484-6c646e9fc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l = []\n",
    "feat_df_l = []\n",
    "time_elapsed_l = []\n",
    "\n",
    "for lclids in tqdm(partitions, desc=\"Training groups...\"):\n",
    "    _train_df = train_df.loc[train_df.LCLid.isin(lclids)]\n",
    "    _test_df = test_df.loc[test_df.LCLid.isin(lclids)]\n",
    "    train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "        _train_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    # Loading the Validation as test\n",
    "    test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "        _test_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    cat_features = set(train_features.columns).intersection(\n",
    "        _feat_config.categorical_features\n",
    "    )\n",
    "    _model_config = model_config.clone()\n",
    "    with LogTime() as timer:\n",
    "        y_pred, feat_df = train_model(\n",
    "            _model_config,\n",
    "            _feat_config,\n",
    "            missing_value_config,\n",
    "            train_features,\n",
    "            train_target,\n",
    "            test_features,\n",
    "            fit_kwargs=dict(categorical_feature=cat_features),\n",
    "        )\n",
    "    y_pred_l.append(y_pred)\n",
    "    feat_df_l.append(feat_df)\n",
    "    time_elapsed_l.append(timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30a9a8-b093-4378-bc9a-cd90b79d47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.concat(y_pred_l)\n",
    "\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = np.sum(time_elapsed_l)\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "#pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925651e-ed0e-4ef5-9238-bf1b445b3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging feature importance across partitions (Dirty Approximation)\n",
    "feat_df = feat_df_l.pop(0)\n",
    "for i, d in enumerate(feat_df_l):\n",
    "    feat_df = feat_df.merge(d, on=\"feature\",suffixes=(\"\",\"_{i}\"))\n",
    "\n",
    "feat_df = feat_df.set_index('feature')\n",
    "feat_df[\"importance\"] = feat_df.sum(axis=1)\n",
    "feat_df = feat_df.reset_index()\n",
    "\n",
    "feat_df = feat_df.loc[:, [\"feature\", \"importance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05457150-cc8a-4b9f-9380-3caa86eb454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Average Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/random_partition_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba5a5c-983d-49b3-b7c8-6c7694ece313",
   "metadata": {},
   "source": [
    "#### Judgmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9a82b-ff75-4efd-af47-75c6693d2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"LCLid\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0411441-323e-4540-b3fd-38aebfac9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params, verbose=-1),\n",
    "    name=\"Tuned GFM+Meta+ACORN Part\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362eea6-5834-4156-a48f-7eb7be5959f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l = []\n",
    "feat_df_l = []\n",
    "time_elapsed_l = []\n",
    "\n",
    "for acn in tqdm(train_df[\"Acorn_grouped\"].unique(), desc=\"Training groups...\"):\n",
    "    _train_df = train_df.loc[train_df.Acorn_grouped == acn]\n",
    "    _test_df = test_df.loc[test_df.Acorn_grouped == acn]\n",
    "    train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "        _train_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    # Loading the Validation as test\n",
    "    test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "        _test_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    cat_features = set(train_features.columns).intersection(\n",
    "        _feat_config.categorical_features\n",
    "    )\n",
    "    _model_config = model_config.clone()\n",
    "    with LogTime() as timer:\n",
    "        y_pred, feat_df = train_model(\n",
    "            _model_config,\n",
    "            _feat_config,\n",
    "            missing_value_config,\n",
    "            train_features,\n",
    "            train_target,\n",
    "            test_features,\n",
    "            fit_kwargs=dict(categorical_feature=cat_features),\n",
    "        )\n",
    "    y_pred_l.append(y_pred)\n",
    "    feat_df_l.append(feat_df)\n",
    "    time_elapsed_l.append(timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b11c8-ff89-43eb-8d7e-55cb7284337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.concat(y_pred_l)\n",
    "\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = np.sum(time_elapsed_l)\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35139b2-8b7b-487f-b01d-a2b00004669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebaef7d-d5a8-489e-891c-96ce14f55cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging feature importance across partitions (Dirty Approximation)\n",
    "\n",
    "feat_df = feat_df_l.pop(0)\n",
    "\n",
    "for i, d in enumerate(feat_df_l):\n",
    "    feat_df = feat_df.merge(d, on=\"feature\",suffixes=(\"\",\"_{i}\"))\n",
    "\n",
    "feat_df = feat_df.set_index('feature')\n",
    "feat_df[\"importance\"] = feat_df.sum(axis=1)\n",
    "feat_df = feat_df.reset_index()\n",
    "\n",
    "feat_df = feat_df.loc[:, [\"feature\", \"importance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b524e-b71e-4069-8710-dc6b2e2c67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Average Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/acorn_partition_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f84cd6-d627-42f3-bad9-e24d8cc14a3f",
   "metadata": {},
   "source": [
    "#### Algorithmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1ce15-a057-4458-b9ef-aa0beefaf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"LCLid\", \"Acorn_grouped\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c3d57-c41e-4e0e-a293-e4df4639b6c4",
   "metadata": {},
   "source": [
    "##### Creating Statistical Features for The Different Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cef1a-e131-4479-9e5d-eeec6a3d3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfel\n",
    "\n",
    "cfg = tsfel.get_features_by_domain(\"statistical\")\n",
    "cfg = {**cfg, **tsfel.get_features_by_domain(\"temporal\")}\n",
    "\n",
    "uniq_ids = train_df.LCLid.cat.categories\n",
    "\n",
    "stat_df = []\n",
    "for id_ in tqdm(uniq_ids, desc=\"Calculating features for all households\"):\n",
    "    ts = train_df.loc[train_df.LCLid==id_, \"energy_consumption\"]\n",
    "    res = tsfel.time_series_features_extractor(cfg, ts, verbose=False)\n",
    "    res['LCLid'] = id_\n",
    "    stat_df.append(res)\n",
    "\n",
    "stat_df = pd.concat(stat_df).set_index(\"LCLid\")\n",
    "del res\n",
    "stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f70074-214b-46f9-b26d-e0b0bd2c503f",
   "metadata": {},
   "source": [
    "##### Clustering The Different Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee5c39-3444-4d6f-9a91-96dfa4d446b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from src.utils.data_utils import replace_array_in_dataframe\n",
    "\n",
    "#T-Distributed Stochastic Neighbor Embedding\n",
    "from sklearn.manifold import TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69464a-682d-4374-ba4c-077c4ec39081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing to make distance calculation fair\n",
    "X_std = replace_array_in_dataframe(stat_df, StandardScaler().fit_transform(stat_df))\n",
    "\n",
    "#Non-Linear Dimensionality Reduction\n",
    "tsne = TSNE(n_components=2, perplexity=50, learning_rate=\"auto\", init=\"pca\", random_state=42, metric=\"cosine\")\n",
    "X_tsne = tsne.fit_transform(X_std.values)\n",
    "\n",
    "# Clustering reduced dimensions into 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(X_tsne)\n",
    "cluster_df = pd.Series(kmeans.labels_, index=X_std.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6d90d-6a3e-49bf-9eeb-b38e327a7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(X_tsne, columns=[\"dim_1\", \"dim_2\"], index=stat_df.index).reset_index()\n",
    "plot_df[\"clusters\"] = kmeans.labels_\n",
    "plot_df[\"clusters\"] = plot_df[\"clusters\"].astype(str)\n",
    "\n",
    "fig = px.scatter(plot_df, x=\"dim_1\", y=\"dim_2\", color=\"clusters\", symbol=\"clusters\", hover_name=\"LCLid\")\n",
    "format_plot(fig, xlabel=\"Dimension 1\", ylabel=\"Dimension 1\", title=f\"Clustered t-SNE\", font_size=12, legends=[\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])\n",
    "# fig.write_image(\"imgs/chapter_10/lin_reg_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e1639-d33e-4146-ba5f-f60a0828adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(plot_df, x=\"dim_1\", y=\"dim_2\", color=\"clusters\", symbol=\"clusters\", hover_name=\"LCLid\")\n",
    "format_plot(fig, xlabel=\"Dimension 1\", ylabel=\"Dimension 1\", title=f\"Clustered t-SNE\", font_size=12, legends=[\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])\n",
    "# fig.write_image(\"imgs/chapter_10/clusters_tsne.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a6818-0c4b-4756-9575-08f423f4cb75",
   "metadata": {},
   "source": [
    "#### Using The Clusters to Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414289b-5c32-4a32-a058-e00248d113d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params, verbose=-1),\n",
    "    name=\"Tuned GFM+Meta+Clustered Part\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bd1a2-c2a1-416f-add4-da3a43432b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l = []\n",
    "feat_df_l = []\n",
    "time_elapsed_l = []\n",
    "\n",
    "for acn in tqdm(cluster_df.unique(), desc=\"Training groups...\"):\n",
    "    lclids = cluster_df[cluster_df==acn].index\n",
    "    _train_df = train_df.loc[train_df.LCLid.isin(lclids)]\n",
    "    _test_df = test_df.loc[test_df.LCLid.isin(lclids)]\n",
    "    train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "        _train_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    # Loading the Validation as test\n",
    "    test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "        _test_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    cat_features = set(train_features.columns).intersection(\n",
    "        _feat_config.categorical_features\n",
    "    )\n",
    "    _model_config = model_config.clone()\n",
    "    with LogTime() as timer:\n",
    "        y_pred, feat_df = train_model(\n",
    "            _model_config,\n",
    "            _feat_config,\n",
    "            missing_value_config,\n",
    "            train_features,\n",
    "            train_target,\n",
    "            test_features,\n",
    "            fit_kwargs=dict(categorical_feature=cat_features),\n",
    "        )\n",
    "    y_pred_l.append(y_pred)\n",
    "    feat_df_l.append(feat_df)\n",
    "    time_elapsed_l.append(timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf94f1-9d19-4e16-9fd7-54b129b20bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.concat(y_pred_l)\n",
    "\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = np.sum(time_elapsed_l)\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500494de-96a2-4495-9f1a-6dce1475ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31515eb2-63f8-4583-b03e-a0237bd122ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging feature importance across partitions (Dirty Approximation)\n",
    "feat_df = feat_df_l.pop(0)\n",
    "for i, d in enumerate(feat_df_l):\n",
    "    feat_df = feat_df.merge(d, on=\"feature\",suffixes=(\"\",\"_{i}\"))\n",
    "\n",
    "feat_df = feat_df.set_index('feature')\n",
    "feat_df[\"importance\"] = feat_df.sum(axis=1)\n",
    "feat_df = feat_df.reset_index()\n",
    "\n",
    "feat_df = feat_df.loc[:, [\"feature\", \"importance\"]].sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c9024-8ff7-4b87-b3e1-10d2b0a87402",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Average Feature Importance - {model_config.name}\", font_size=12)\n",
    "# fig.write_image(\"imgs/chapter_10/clustered_partition_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ba03e-efcc-45ce-97e0-b36b32f2c1ae",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272928f7-8900-4da8-b538-b22cb75a739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(np.abs(s.values)), props, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee0488-6f1a-44c2-9017-048e00fe6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics = pd.DataFrame(metric_record)\n",
    "agg_metrics.style.format(\n",
    "    {\"MAE\": \"{:.4f}\", \"MSE\": \"{:.4f}\", \"meanMASE\": \"{:.4f}\", \"Forecast Bias\": \"{:.2f}%\"}\n",
    ").highlight_min(color=\"lightgreen\", subset=[\"MAE\", \"MSE\", \"meanMASE\"]).apply(\n",
    "    highlight_abs_min,\n",
    "    props=\"color:black;background-color:lightgreen\",\n",
    "    axis=0,\n",
    "    subset=[\"Forecast Bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f65be6-3a10-4a96-b0d8-03958e6ed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ff61c-5c88-4154-b93b-70a5a0b147ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_metrics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449d12d-6776-4789-876f-360f249103f9",
   "metadata": {},
   "source": [
    "## Saving `The GFM Forecasts and Metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77b5e5-5104-4043-86c0-ded764f0d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/london_smart_meters/output\", exist_ok=True)\n",
    "\n",
    "output = Path(\"data/london_smart_meters/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7c8c8-3901-4280-b549-1f453ba047cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_pickle(output/\"gfm_predictions_test_df.pkl\")\n",
    "\n",
    "joblib.dump(individual_metrics, output/\"gfm_metrics_test_df.pkl\")\n",
    "\n",
    "agg_metrics.to_pickle(output/\"gfm_aggregate_metrics_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13509353-1bdb-45ca-b7b1-870bd1929b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MTSP] *",
   "language": "python",
   "name": "conda-env-MTSP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
