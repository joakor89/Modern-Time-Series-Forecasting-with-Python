{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e84363c-d348-4425-ae12-ed79ba5998a6",
   "metadata": {},
   "source": [
    "# Global Forecasting Models (ML)\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bb9b00-9216-403c-aa9a-cb655965bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joaquinromero/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d31e5-edec-4580-9d06-d8fd7459789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# OS & Time\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# Warnings, Func & Path\n",
    "import warnings\n",
    "import pickleshare\n",
    "import missingno as msno\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "\n",
    "# PyArrow\n",
    "import pyarrow as pa\n",
    "\n",
    "# Humanize\n",
    "import humanize\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# IPython - Display\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Random\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14b035-17d5-4699-820a-fdbdc5c43991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from src.utils import plotting_utils\n",
    "from src.utils.general import LogTime\n",
    "from src.utils.data_utils import _get_32_bit_dtype \n",
    "from src.utils.ts_utils_updated import metrics_adapter, forecast_bias,mae, mase, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef92dd-a67b-416f-8c1f-30ac0a183ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.forecasting.ml_forecasting import (\n",
    "    FeatureConfig,\n",
    "    MissingValueConfig,\n",
    "    MLForecast,\n",
    "    ModelConfig,\n",
    "    calculate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939f912-1d09-4209-9a77-965fb48659bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60631530-cca5-42ee-b64f-376790a1c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206ea96-0316-48ee-b3d8-e274a40bd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_10\", exist_ok=True)\n",
    "\n",
    "preprocessed = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"preprocessed\"\n",
    "\n",
    "output = Path.home() / \"Desktop\" / \"data\" / \"london_smart_meters\" / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d383836-10a1-4e8c-931a-6e2817631dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.9,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edd8b9-ddc8-48f9-b276-c1f1d06db670",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"block_0-7_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31224484-989e-4c94-a3a4-ebfa277757bc",
   "metadata": {},
   "source": [
    "#### Loading `The Single Step Backtesting Baselines` for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dddc5a-a8bb-465c-adef-656af5e4811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    baseline_aggregate_metrics_df = pd.read_pickle(output/\"ml_single_step_aggregate_metrics_auto_stationary_val.pkl\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 02-Forecasting with Target Transformation.ipynb in Chapter08\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59323193-19f5-45d1-b9fb-345818f2e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df.LCLid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3ef95-743d-4725-b7c4-d1de8343ddce",
   "metadata": {},
   "source": [
    "### Feature Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7daf1b1c-b57f-40c5-a883-2482c17b6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    date=\"timestamp\",\n",
    "    target=\"energy_consumption\",\n",
    "    continuous_features=[\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma_span_2880\",\n",
    "        \"energy_consumption_ewma_span_336\",\n",
    "        \"energy_consumption_ewma_span_48\",\n",
    "        \"timestamp_Elapsed\",\n",
    "        \"timestamp_Month_sin_1\",\n",
    "        \"timestamp_Month_sin_2\",\n",
    "        \"timestamp_Month_sin_3\",\n",
    "        \"timestamp_Month_sin_4\",\n",
    "        \"timestamp_Month_sin_5\",\n",
    "        \"timestamp_Month_cos_1\",\n",
    "        \"timestamp_Month_cos_2\",\n",
    "        \"timestamp_Month_cos_3\",\n",
    "        \"timestamp_Month_cos_4\",\n",
    "        \"timestamp_Month_cos_5\",\n",
    "        \"timestamp_Hour_sin_1\",\n",
    "        \"timestamp_Hour_sin_2\",\n",
    "        \"timestamp_Hour_sin_3\",\n",
    "        \"timestamp_Hour_sin_4\",\n",
    "        \"timestamp_Hour_sin_5\",\n",
    "        \"timestamp_Hour_cos_1\",\n",
    "        \"timestamp_Hour_cos_2\",\n",
    "        \"timestamp_Hour_cos_3\",\n",
    "        \"timestamp_Hour_cos_4\",\n",
    "        \"timestamp_Hour_cos_5\",\n",
    "        \"timestamp_Minute_sin_1\",\n",
    "        \"timestamp_Minute_sin_2\",\n",
    "        \"timestamp_Minute_sin_3\",\n",
    "        \"timestamp_Minute_sin_4\",\n",
    "        \"timestamp_Minute_sin_5\",\n",
    "        \"timestamp_Minute_cos_1\",\n",
    "        \"timestamp_Minute_cos_2\",\n",
    "        \"timestamp_Minute_cos_3\",\n",
    "        \"timestamp_Minute_cos_4\",\n",
    "        \"timestamp_Minute_cos_5\",\n",
    "    ],\n",
    "    categorical_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"timestamp_Month\",\n",
    "        \"timestamp_Quarter\",\n",
    "        \"timestamp_WeekDay\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "        \"timestamp_Dayofyear\",\n",
    "        \"timestamp_Hour\",\n",
    "        \"timestamp_Minute\"\n",
    "    ],\n",
    "    boolean_features=[\n",
    "        \"timestamp_Is_quarter_end\",\n",
    "        \"timestamp_Is_quarter_start\",\n",
    "        \"timestamp_Is_year_end\",\n",
    "        \"timestamp_Is_year_start\",\n",
    "        \"timestamp_Is_month_start\",\n",
    "    ],\n",
    "    index_cols=[\"LCLid\",\"timestamp\"],\n",
    "    exogenous_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9931f19-eeaa-4507-a321-01908232d5a8",
   "metadata": {},
   "source": [
    "### Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf401f-a072-4236-906d-2a743825a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_config = MissingValueConfig(\n",
    "    bfill_columns=[\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma__span_2880\",\n",
    "        \"energy_consumption_ewma__span_336\",\n",
    "        \"energy_consumption_ewma__span_48\",\n",
    "    ],\n",
    "    ffill_columns=[],\n",
    "    zero_fill_columns=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49b14b-cd75-45c7-b05d-9704e91de490",
   "metadata": {},
   "source": [
    "## Training Global ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861b468-c3c5-4d27-8224-9d975deea5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ts_utils_updated\n",
    "\n",
    "from src.forecasting.ml_forecasting import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ad9c-35b6-4910-8797-1d0d0adbe383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model_config,\n",
    "    feature_config,\n",
    "    missing_config,\n",
    "    train_features,\n",
    "    train_target,\n",
    "    test_features,\n",
    "    fit_kwargs={}\n",
    "):\n",
    "    ml_model = MLForecast(\n",
    "        model_config=model_config,\n",
    "        feature_config=feature_config,\n",
    "        missing_config=missing_config,\n",
    "    )\n",
    "    ml_model.fit(train_features, train_target, fit_kwargs=fit_kwargs)\n",
    "    y_pred = ml_model.predict(test_features)\n",
    "    feat_df = ml_model.feature_importance()\n",
    "    return y_pred, feat_df\n",
    "\n",
    "def evaluate_forecast(y_pred, test_target, train_target, model_config):\n",
    "    metric_l = []\n",
    "    for _id in tqdm(test_target.index.get_level_values(0).remove_unused_categories().categories, desc=\"Calculating metrics...\"):\n",
    "        target = test_target.xs(_id)\n",
    "        _y_pred = y_pred.xs(_id)\n",
    "        history = train_target.xs(_id)\n",
    "        metric_l.append(\n",
    "            calculate_metrics(target, _y_pred, name=model_config.name, y_train=history)\n",
    "        )\n",
    "    eval_metrics_df = pd.DataFrame(metric_l)\n",
    "    agg_metrics = {\n",
    "            \"Algorithm\": model_config.name,\n",
    "            \"MAE\": ts_utils.mae(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ),\n",
    "            \"MSE\": ts_utils.mse(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ),\n",
    "            \"meanMASE\": eval_metrics_df.loc[:, \"MASE\"].mean(),\n",
    "            \"Forecast Bias\": ts_utils.forecast_bias_aggregate(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            )\n",
    "    }\n",
    "    return agg_metrics, eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d89c5-55e5-482c-a67c-2ca51e4ce318",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record = []\n",
    "individual_metrics = dict()\n",
    "\n",
    "metric_record = (\n",
    "    baseline_aggregate_metrics_df.iloc[[4]]\n",
    "    .to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47925a38-4e6d-4124-a68c-371d63152d71",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8e742-c0fd-4c94-9d03-50f29d0b9366",
   "metadata": {},
   "outputs": [],
   "source": [
    "_feat_config = copy.deepcopy(feat_config)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=False, exogenous=False\n",
    ")\n",
    "\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=False, exogenous=False\n",
    ")\n",
    "\n",
    "pred_df = test_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345db4a1-9d9c-4ebf-907f-2036c276dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM Baseline\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83f1ac-3304-4683-ac8f-11540300dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    y_pred, test_target, train_target, model_config\n",
    ")\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc27703-6c3d-471e-a6bf-2d73c2820ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab211b1-29fd-4d0b-85f2-2ba462ab91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/baseline_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2786a-4e09-49f1-83a0-cec9bb8bed7c",
   "metadata": {},
   "source": [
    "### With Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9b7c3-c6d8-4273-9d9d-6a525ec57eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"Acorn_grouped\", \"LCLid\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "cat_features = set(train_features.columns).intersection(_feat_config.categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b28344-733c-491c-b2b8-15b35bff5eea",
   "metadata": {},
   "source": [
    "#### CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6726b-5805-42e4-b0ad-9cb092064825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from category_encoders import CountEncoder\n",
    "\n",
    "cat_encoder = CountEncoder(cols=cat_features)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta (CountEncoder)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    "    encode_categorical=True,\n",
    "    categorical_encoder=cat_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f6689-1ec4-4a8d-9253-0fa21d6ae7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_feat_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fc95c-85ac-4ab6-bc1b-14285ad3716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def55de-bdd7-4bd1-aa3f-9b728c4756f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b1ab2-0de6-49d5-bab4-9e8fd4253310",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/baseline_w_meta_cnt_encoder_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b34f1-0cdd-49cb-ae0a-d5d8a4b5efae",
   "metadata": {},
   "source": [
    "#### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2f868-a40a-4c01-970b-bab8cb1213e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6f66f-c578-4f04-bb59-f4a3e4363f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "cat_encoder = TargetEncoder(cols=cat_features)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta  (TargetEncoder)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    "    encode_categorical=True,\n",
    "    categorical_encoder=cat_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40577e4c-c4ad-4065-92b1-a90f932ceaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243f16c-a742-423d-9212-6295566873c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db2f3c-da43-4577-b9a5-94deefb00545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/baseline_w_meta_tgt_encoder_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22c968-9055-49c3-8caf-4f28b4c53a1d",
   "metadata": {},
   "source": [
    "#### Native LightGBM Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6468240-a4da-4cee-897e-faea57a78f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(random_state=42),\n",
    "    name=\"GFM+Meta  (NativeLGBM)\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    "    # We are using inbuilt categorical feature handling\n",
    "    encode_categorical=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1eabe-e40f-4e18-aaaa-13e4b8e2b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features),\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1addba2-2e6a-4204-97d1-a418fbdd59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd18358-41a2-423d-8517-ad3fea109f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/baseline_w_meta_native_lgbm_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd9e46-da20-4f9c-9bd8-a30fe21e6339",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422e8dc-320e-44f1-ae0c-66e8cc38ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"Acorn_grouped\", \"LCLid\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)\n",
    "\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "# Loading the Validation as test\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "cat_features = set(train_features.columns).intersection(_feat_config.categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fa62c-2862-41c8-a64f-4685b3c2f5a2",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c32aa-06f5-43a5-be4d-96bc9ee3653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "grid_params = {\n",
    "    \"num_leaves\": [16, 31, 63],\n",
    "    \"objective\": [\"regression\", \"regression_l1\", \"huber\"],\n",
    "    \"random_state\": [42],\n",
    "    \"colsample_bytree\": [0.5, 0.8, 1.0],\n",
    "}\n",
    "parameter_space = list(ParameterGrid(grid_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cefa5-466a-445f-a8f3-848e74362e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use PredefinedSplit along with GridSearchCV to have the search done faster using multi-processing\n",
    "# Or we can parallelize the loop ourselves\n",
    "scores = []\n",
    "for p in tqdm(parameter_space, desc=\"Performing Grid Search\"):\n",
    "    _model_config = ModelConfig(\n",
    "        model=LGBMRegressor(**p, verbose=-1),\n",
    "        name=\"Global Meta LightGBM Tuning\",\n",
    "        # LGBM is not sensitive to normalized data\n",
    "        normalize=False,\n",
    "        # LGBM can handle missing values\n",
    "        fill_missing=False,\n",
    "    )\n",
    "    y_pred, feat_df = train_model(\n",
    "        _model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features),\n",
    "    )\n",
    "    scores.append(ts_utils.mae(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2539b-552a-4028-bf44-604bdbf51094",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_trials = pd.DataFrame({\"params\":parameter_space, \"score\":scores}).sort_values(\"score\")\n",
    "best_params_gs = grid_search_trials.iloc[0,0]\n",
    "best_score_gs = grid_search_trials.iloc[0,1]\n",
    "grid_search_trials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a5235-f774-4e03-97b1-f8174c11ffc7",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660135d-411b-4482-aa6e-ad036ad52e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "random_search_params = {\n",
    "    # A uniform distribution between 10 and 100, but only integers\n",
    "    \"num_leaves\": scipy.stats.randint(10,100),\n",
    "    # A list of categorical string values\n",
    "    \"objective\": [\"regression\", \"regression_l1\", \"huber\"],\n",
    "    \"random_state\": [42],\n",
    "    # List of floating point numbers between 0.3 and 1.0 with a resolution of 0.05\n",
    "    \"colsample_bytree\": np.arange(0.3,1.0,0.05),\n",
    "    # List of floating point numbers between 0 and 10 with a resolution of 0.1\n",
    "    \"lambda_l1\":np.arange(0,10,0.1),\n",
    "    # List of floating point numbers between 0 and 10 with a resolution of 0.1\n",
    "    \"lambda_l2\":np.arange(0,10,0.1)\n",
    "}\n",
    "# Sampling from the search space number of iterations times\n",
    "parameter_space = list(ParameterSampler(random_search_params, n_iter=27, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f6369-f0a8-4917-8315-2541bb3ad9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use PredefinedSplit along with RandomSearchCV to have the search done faster using multi-processing\n",
    "# Or we can parallelize the loop ourselves\n",
    "scores = []\n",
    "for p in tqdm(parameter_space, desc=\"Performing Random Search\"):\n",
    "    _model_config = ModelConfig(\n",
    "        model=LGBMRegressor(**p, verbose=-1),\n",
    "        name=\"Global Meta LightGBM Tuning\",\n",
    "        # LGBM is not sensitive to normalized data\n",
    "        normalize=False,\n",
    "        # LGBM can handle missing values\n",
    "        fill_missing=False,\n",
    "    )\n",
    "    y_pred, feat_df = train_model(\n",
    "        _model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features),\n",
    "    )\n",
    "    scores.append(ts_utils.mae(\n",
    "                test_target['energy_consumption'], y_pred\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105be63-fd02-4098-bf82-4078731c26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_trials = pd.DataFrame({\"params\":parameter_space, \"score\":scores}).sort_values(\"score\")\n",
    "best_params_rs = random_search_trials.iloc[0,0]\n",
    "best_score_rs = random_search_trials.iloc[0,1]\n",
    "random_search_trials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e7593-688d-4b0f-bdf3-eb5aa07a8173",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a0901-c82f-46d8-9152-8c419cb93dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30897d0d-5500-44e9-9fde-414eb5747162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective functions which takes in trial as a parameter \n",
    "# and evaluates the model with the generated params\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # Sample an integer between 10 and 100\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 100),\n",
    "        # Sample a categorical value from the list provided\n",
    "        \"objective\": trial.suggest_categorical(\n",
    "            \"objective\", [\"regression\", \"regression_l1\", \"huber\"]\n",
    "        ),\n",
    "        \"random_state\": [42],\n",
    "        # Sample from a uniform distribution between 0.3 and 1.0\n",
    "        \"colsample_bytree\": trial.suggest_float (\"colsample_bytree\", 0.3, 1.0),\n",
    "        # Sample from a uniform distribution between 0 and 10\n",
    "        \"lambda_l1\": trial.suggest_float (\"lambda_l1\", 0, 10),\n",
    "        # Sample from a uniform distribution between 0 and 10\n",
    "        \"lambda_l2\": trial.suggest_float (\"lambda_l2\", 0, 10),\n",
    "    }\n",
    "    _model_config = ModelConfig(\n",
    "        # Use the sampled params to initialize the model\n",
    "        model=LGBMRegressor(**params, verbose=-1),\n",
    "        name=\"Global Meta LightGBM Tuning\",\n",
    "        # LGBM is not sensitive to normalized data\n",
    "        normalize=False,\n",
    "        # LGBM can handle missing values\n",
    "        fill_missing=False,\n",
    "    )\n",
    "    y_pred, feat_df = train_model(\n",
    "        _model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features),\n",
    "    )\n",
    "    # Return the MAE metric as the value\n",
    "    return ts_utils.mae(test_target[\"energy_consumption\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bf71a-808c-4c81-acc7-fdae9048bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sampler and set seed for repeatability. \n",
    "# Set startup trials as 5 because out total trials is lower.\n",
    "sampler = optuna.samplers.TPESampler(n_startup_trials=5, seed=42)\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# Start the optimization run\n",
    "study.optimize(objective, n_trials=27, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb708d4-d617-47c2-adc5-73795acfb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_search_trials = study.trials_dataframe()\n",
    "best_params_bo = study.best_params\n",
    "best_score_bo = study.best_value\n",
    "bo_search_trials.sort_values(\"value\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26b18b-9861-4282-a59f-a49d9082ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d8b80-2a41-423e-9864-43f44d6f040f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Techniques (Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaa045-c847-42bf-ac76-76dbcc73db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_history(trials_df):\n",
    "    plot_df = trials_df.sort_index()\n",
    "    plot_df['best'] = plot_df.score.expanding().min()\n",
    "\n",
    "    x = plot_df.reset_index().index\n",
    "    fig = go.Figure(layout=dict(title=\"Optimization History Plot\"))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=plot_df.score,\n",
    "            mode='markers',\n",
    "            name=\"Objective\"\n",
    "        ))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=plot_df.best,\n",
    "            mode='lines',\n",
    "            name=\"Best Value\"\n",
    "        ))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445373f5-b414-466a-865f-4f0d962cec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_optimization_history(grid_search_trials)\n",
    "fig = format_plot(fig, xlabel=\"# Trials\", ylabel=\"Objective Value\", title=\"Optimization History Plot (Grid Search)\")\n",
    "fig.write_image(\"imgs/chapter_10/opt_history_gs.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ad17e-322d-4ac1-bc0b-8cf0993a998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_optimization_history(random_search_trials)\n",
    "fig = format_plot(fig, xlabel=\"# Trials\", ylabel=\"Objective Value\", title=\"Optimization History Plot (Random Search)\")\n",
    "fig.write_image(\"imgs/chapter_10/opt_history_rs.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f5ed6-4ef3-4ef6-8094-7c85993d2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig = format_plot(fig, xlabel=\"# Trials\", ylabel=\"Objective Value\", title=\"Optimization History Plot (Bayesian Optimization)\")\n",
    "fig.write_image(\"imgs/chapter_10/opt_history_bo.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efcca7-b906-49fb-ac56-353a7120ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({\"Optimization\": [\"Grid Search\", \"Random Search\", \"Bayesian Optimization\"], \"Best Score\": [best_score_gs, best_score_rs, best_score_bo]}).sort_values(by = ['Best Score'],\n",
    "                    ascending = True)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6a0f1-fd45-45ba-b11d-d6e8cda93e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = grid_search_trials.copy()\n",
    "plot_df['optimization'] = \"Grid Search\"\n",
    "plot_df.drop(columns=\"params\", inplace=True)\n",
    "\n",
    "df_ = random_search_trials.copy()\n",
    "df_['optimization'] = \"Random Search\"\n",
    "df_.drop(columns=\"params\", inplace=True)\n",
    "plot_df = pd.concat([plot_df, df_])\n",
    "\n",
    "df_ = bo_search_trials.copy()\n",
    "df_['optimization'] = \"Bayesian Optimization\"\n",
    "df_.rename(columns={\"value\": \"score\"}, inplace=True)\n",
    "df_ = df_[[\"score\", \"optimization\"]]\n",
    "plot_df = pd.concat([plot_df, df_])\n",
    "\n",
    "fig = px.violin(plot_df, y=\"score\", color=\"optimization\",  points=False)\n",
    "fig = format_plot(fig, xlabel=\"Optimization Techniques\", ylabel=\"Objective Value\", title=\"Objective Function Evaluation of Different Optimization Techniques\")\n",
    "fig.write_image(\"imgs/chapter_10/opt_violin.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ebec8-4732-4b4b-839f-adad00cd9000",
   "metadata": {},
   "source": [
    "#### Using The Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02225-fab2-4c78-ba66-3e317fd7b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = study.best_params\n",
    "# best_params['random_state'] = 42\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c35f68-3d53-4cd3-8ba4-3c06aa3c3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"num_leaves\": 99,\n",
    "    \"objective\": \"regression_l1\",\n",
    "    \"colsample_bytree\": 0.9786759775515064,\n",
    "    \"lambda_l1\": 8.160098582954642,\n",
    "    \"lambda_l2\": 0.17840888757497253,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288e1bc-eb74-4bf8-824a-3750b09e15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params),\n",
    "    name=\"Tuned GFM+Meta\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aca643-231d-429f-99a5-34824b5e1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogTime() as timer:\n",
    "    y_pred, feat_df = train_model(\n",
    "        model_config,\n",
    "        _feat_config,\n",
    "        missing_value_config,\n",
    "        train_features,\n",
    "        train_target,\n",
    "        test_features,\n",
    "        fit_kwargs=dict(categorical_feature=cat_features)\n",
    "    )\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = timer.elapsed\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77347aa-7a86-45cd-8368-158db2bb78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94e903-ba56-4b20-bab8-ae901f6fe670",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/tuned_meta_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b176f-e30d-4b84-b5bb-9780591dba25",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696ae23-e9f3-4ecf-a643-4637f3c28913",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"num_leaves\": 99,\n",
    "    \"objective\": \"regression_l1\",\n",
    "    \"colsample_bytree\": 0.9786759775515064,\n",
    "    \"lambda_l1\": 8.160098582954642,\n",
    "    \"lambda_l2\": 0.17840888757497253,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe121c59-05ce-4aff-aebb-ce4081a713ad",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56750b-664c-455e-91f7-7cfe13aec530",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conf_dict = copy.deepcopy(feat_config.__dict__)\n",
    "feat_conf_dict.pop(\"feature_list\")\n",
    "feat_conf_dict['categorical_features']+=[\"stdorToU\", \"Acorn\", \"LCLid\", \"Acorn_grouped\"]\n",
    "_feat_config = FeatureConfig(**feat_conf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339b52d-a84d-4167-a12a-02e2908e88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model=LGBMRegressor(**best_params, verbose=-1),\n",
    "    name=\"Tuned GFM+Meta+Random Part\",\n",
    "    # LGBM is not sensitive to normalized data\n",
    "    normalize=False,\n",
    "    # LGBM can handle missing values\n",
    "    fill_missing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dbc6cb-2e9c-4c0a-9f1a-f8f6bd29f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (list_in, n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "partitions = partition(train_df.LCLid.cat.categories.tolist(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b2937-ea11-4cc2-bf0d-637062315fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l = []\n",
    "feat_df_l = []\n",
    "time_elapsed_l = []\n",
    "\n",
    "for lclids in tqdm(partitions, desc=\"Training groups...\"):\n",
    "    _train_df = train_df.loc[train_df.LCLid.isin(lclids)]\n",
    "    _test_df = test_df.loc[test_df.LCLid.isin(lclids)]\n",
    "    train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "        _train_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    # Loading the Validation as test\n",
    "    test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "        _test_df, categorical=True, exogenous=False\n",
    "    )\n",
    "    cat_features = set(train_features.columns).intersection(\n",
    "        _feat_config.categorical_features\n",
    "    )\n",
    "    _model_config = model_config.clone()\n",
    "    with LogTime() as timer:\n",
    "        y_pred, feat_df = train_model(\n",
    "            _model_config,\n",
    "            _feat_config,\n",
    "            missing_value_config,\n",
    "            train_features,\n",
    "            train_target,\n",
    "            test_features,\n",
    "            fit_kwargs=dict(categorical_feature=cat_features),\n",
    "        )\n",
    "    y_pred_l.append(y_pred)\n",
    "    feat_df_l.append(feat_df)\n",
    "    time_elapsed_l.append(timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e8e71-b7e3-44b6-ae3d-2385a293b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.concat(y_pred_l)\n",
    "\n",
    "test_features, test_target, test_original_target = _feat_config.get_X_y(\n",
    "    test_df, categorical=True, exogenous=False\n",
    ")\n",
    "train_features, train_target, train_original_target = _feat_config.get_X_y(\n",
    "    train_df, categorical=True, exogenous=False\n",
    ")\n",
    "\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(y_pred, test_target, train_target, model_config)\n",
    "agg_metrics[\"Time Elapsed\"] = np.sum(time_elapsed_l)\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[model_config.name]=eval_metrics_df\n",
    "pred_df = pred_df.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af265f90-3f17-4e94-8388-573b2d221c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d8cbd-181f-43b1-a0f9-120aecf05382",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aaa7a9-f583-4d9d-b492-d225f3455bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = feat_df_l.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1d13f-0ae7-4def-976a-a26f77130a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f8d4c-310f-4bbd-9b51-dcb7b8e240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging feature importance across partitions (Dirty Approximation)\n",
    "feat_df = feat_df_l.pop(0)\n",
    "for i, d in enumerate(feat_df_l):\n",
    "    feat_df = feat_df.merge(d, on=\"feature\",suffixes=(\"\",\"_{i}\"))\n",
    "\n",
    "feat_df = feat_df.set_index('feature')\n",
    "feat_df[\"importance\"] = feat_df.sum(axis=1)\n",
    "feat_df = feat_df.reset_index()\n",
    "feat_df = feat_df.loc[:, [\"feature\", \"importance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de74c82-a4d7-41c9-9430-7cec0788c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feat_df.head(15), x=\"feature\", y=\"importance\")\n",
    "format_plot(fig, xlabel=\"Features\", ylabel=\"Importance\", title=f\"Aggregate Feature Importance - {model_config.name}\", font_size=12)\n",
    "fig.write_image(\"imgs/chapter_10/random_partition_fimp.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba2563-4630-426e-bf98-6851733af4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Judgmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4636eb7-6faf-4064-82f5-47c9118ce303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaf621-d488-4d0c-ba1e-93c5ff8c66e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2eb8ea-fa32-4807-8304-bb356d193412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a07e21-bcd1-46f2-9cf9-0fde49da5ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68cd9e-3637-4f77-8530-6f5e1690366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01454c4c-5a59-4b77-aac8-5331a7013527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12689cd8-0e3b-45df-a92d-14d5d088a037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0250-2420-4072-b1f9-7cf6300adad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6984cab-ec5d-45f4-9a70-d0a4ae642593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MTSP)",
   "language": "python",
   "name": "mtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
